{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 11460,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.013089005235602094,
      "grad_norm": 0.12118277698755264,
      "learning_rate": 1.9912739965095987e-05,
      "loss": 1.115,
      "step": 50
    },
    {
      "epoch": 0.02617801047120419,
      "grad_norm": 0.17336107790470123,
      "learning_rate": 1.9825479930191973e-05,
      "loss": 1.1158,
      "step": 100
    },
    {
      "epoch": 0.03926701570680628,
      "grad_norm": 0.3817252516746521,
      "learning_rate": 1.973821989528796e-05,
      "loss": 1.1155,
      "step": 150
    },
    {
      "epoch": 0.05235602094240838,
      "grad_norm": 0.20205768942832947,
      "learning_rate": 1.9650959860383945e-05,
      "loss": 1.116,
      "step": 200
    },
    {
      "epoch": 0.06544502617801047,
      "grad_norm": 0.19136646389961243,
      "learning_rate": 1.956369982547993e-05,
      "loss": 1.0893,
      "step": 250
    },
    {
      "epoch": 0.07853403141361257,
      "grad_norm": 0.3084053099155426,
      "learning_rate": 1.947643979057592e-05,
      "loss": 1.0854,
      "step": 300
    },
    {
      "epoch": 0.09162303664921466,
      "grad_norm": 0.32901453971862793,
      "learning_rate": 1.9389179755671902e-05,
      "loss": 1.0923,
      "step": 350
    },
    {
      "epoch": 0.10471204188481675,
      "grad_norm": 0.32096418738365173,
      "learning_rate": 1.930191972076789e-05,
      "loss": 1.0846,
      "step": 400
    },
    {
      "epoch": 0.11780104712041885,
      "grad_norm": 0.3386801481246948,
      "learning_rate": 1.9214659685863877e-05,
      "loss": 1.084,
      "step": 450
    },
    {
      "epoch": 0.13089005235602094,
      "grad_norm": 0.46849507093429565,
      "learning_rate": 1.9127399650959863e-05,
      "loss": 1.0753,
      "step": 500
    },
    {
      "epoch": 0.14397905759162305,
      "grad_norm": 0.373625785112381,
      "learning_rate": 1.904013961605585e-05,
      "loss": 1.0676,
      "step": 550
    },
    {
      "epoch": 0.15706806282722513,
      "grad_norm": 0.6743139028549194,
      "learning_rate": 1.895287958115183e-05,
      "loss": 1.0772,
      "step": 600
    },
    {
      "epoch": 0.17015706806282724,
      "grad_norm": 0.506660521030426,
      "learning_rate": 1.886561954624782e-05,
      "loss": 1.0668,
      "step": 650
    },
    {
      "epoch": 0.18324607329842932,
      "grad_norm": 0.4669664800167084,
      "learning_rate": 1.8778359511343806e-05,
      "loss": 1.0579,
      "step": 700
    },
    {
      "epoch": 0.19633507853403143,
      "grad_norm": 1.4325381517410278,
      "learning_rate": 1.8691099476439792e-05,
      "loss": 1.0444,
      "step": 750
    },
    {
      "epoch": 0.2094240837696335,
      "grad_norm": 0.841909646987915,
      "learning_rate": 1.8603839441535778e-05,
      "loss": 1.0404,
      "step": 800
    },
    {
      "epoch": 0.22251308900523561,
      "grad_norm": 0.9710665941238403,
      "learning_rate": 1.8516579406631764e-05,
      "loss": 1.0468,
      "step": 850
    },
    {
      "epoch": 0.2356020942408377,
      "grad_norm": 0.4884214401245117,
      "learning_rate": 1.842931937172775e-05,
      "loss": 1.0239,
      "step": 900
    },
    {
      "epoch": 0.2486910994764398,
      "grad_norm": 1.8202688694000244,
      "learning_rate": 1.8342059336823735e-05,
      "loss": 1.0434,
      "step": 950
    },
    {
      "epoch": 0.2617801047120419,
      "grad_norm": 0.9531408548355103,
      "learning_rate": 1.825479930191972e-05,
      "loss": 1.0427,
      "step": 1000
    },
    {
      "epoch": 0.27486910994764396,
      "grad_norm": 0.487871915102005,
      "learning_rate": 1.8167539267015707e-05,
      "loss": 1.0428,
      "step": 1050
    },
    {
      "epoch": 0.2879581151832461,
      "grad_norm": 1.1555445194244385,
      "learning_rate": 1.8080279232111696e-05,
      "loss": 1.0366,
      "step": 1100
    },
    {
      "epoch": 0.3010471204188482,
      "grad_norm": 0.6162355542182922,
      "learning_rate": 1.799301919720768e-05,
      "loss": 1.0178,
      "step": 1150
    },
    {
      "epoch": 0.31413612565445026,
      "grad_norm": 0.6140527129173279,
      "learning_rate": 1.7905759162303668e-05,
      "loss": 1.0302,
      "step": 1200
    },
    {
      "epoch": 0.32722513089005234,
      "grad_norm": 0.6246379017829895,
      "learning_rate": 1.7818499127399654e-05,
      "loss": 1.0312,
      "step": 1250
    },
    {
      "epoch": 0.3403141361256545,
      "grad_norm": 0.7229703664779663,
      "learning_rate": 1.773123909249564e-05,
      "loss": 1.0313,
      "step": 1300
    },
    {
      "epoch": 0.35340314136125656,
      "grad_norm": 1.373700499534607,
      "learning_rate": 1.7643979057591625e-05,
      "loss": 1.0133,
      "step": 1350
    },
    {
      "epoch": 0.36649214659685864,
      "grad_norm": 0.9335792660713196,
      "learning_rate": 1.755671902268761e-05,
      "loss": 1.033,
      "step": 1400
    },
    {
      "epoch": 0.3795811518324607,
      "grad_norm": 2.1842923164367676,
      "learning_rate": 1.7469458987783597e-05,
      "loss": 1.0192,
      "step": 1450
    },
    {
      "epoch": 0.39267015706806285,
      "grad_norm": 0.8742027282714844,
      "learning_rate": 1.7382198952879583e-05,
      "loss": 1.0349,
      "step": 1500
    },
    {
      "epoch": 0.40575916230366493,
      "grad_norm": 0.6279504895210266,
      "learning_rate": 1.729493891797557e-05,
      "loss": 1.0252,
      "step": 1550
    },
    {
      "epoch": 0.418848167539267,
      "grad_norm": 0.8896008729934692,
      "learning_rate": 1.7207678883071554e-05,
      "loss": 1.0386,
      "step": 1600
    },
    {
      "epoch": 0.4319371727748691,
      "grad_norm": 0.57406085729599,
      "learning_rate": 1.712041884816754e-05,
      "loss": 1.028,
      "step": 1650
    },
    {
      "epoch": 0.44502617801047123,
      "grad_norm": 0.6361834406852722,
      "learning_rate": 1.7033158813263526e-05,
      "loss": 1.0141,
      "step": 1700
    },
    {
      "epoch": 0.4581151832460733,
      "grad_norm": 0.49638131260871887,
      "learning_rate": 1.694589877835951e-05,
      "loss": 1.0103,
      "step": 1750
    },
    {
      "epoch": 0.4712041884816754,
      "grad_norm": 2.087602376937866,
      "learning_rate": 1.6858638743455497e-05,
      "loss": 1.0076,
      "step": 1800
    },
    {
      "epoch": 0.48429319371727747,
      "grad_norm": 0.8858644366264343,
      "learning_rate": 1.6771378708551483e-05,
      "loss": 1.0138,
      "step": 1850
    },
    {
      "epoch": 0.4973821989528796,
      "grad_norm": 0.9705279469490051,
      "learning_rate": 1.6684118673647472e-05,
      "loss": 1.0266,
      "step": 1900
    },
    {
      "epoch": 0.5104712041884817,
      "grad_norm": 0.9348119497299194,
      "learning_rate": 1.6596858638743455e-05,
      "loss": 1.0013,
      "step": 1950
    },
    {
      "epoch": 0.5235602094240838,
      "grad_norm": 0.8809092044830322,
      "learning_rate": 1.6509598603839444e-05,
      "loss": 1.0176,
      "step": 2000
    },
    {
      "epoch": 0.5366492146596858,
      "grad_norm": 0.9426864981651306,
      "learning_rate": 1.642233856893543e-05,
      "loss": 0.9743,
      "step": 2050
    },
    {
      "epoch": 0.5497382198952879,
      "grad_norm": 1.5908390283584595,
      "learning_rate": 1.6335078534031416e-05,
      "loss": 0.9934,
      "step": 2100
    },
    {
      "epoch": 0.56282722513089,
      "grad_norm": 0.6813254356384277,
      "learning_rate": 1.62478184991274e-05,
      "loss": 1.0186,
      "step": 2150
    },
    {
      "epoch": 0.5759162303664922,
      "grad_norm": 2.6370980739593506,
      "learning_rate": 1.6160558464223387e-05,
      "loss": 0.9976,
      "step": 2200
    },
    {
      "epoch": 0.5890052356020943,
      "grad_norm": 0.702314555644989,
      "learning_rate": 1.6073298429319373e-05,
      "loss": 1.0086,
      "step": 2250
    },
    {
      "epoch": 0.6020942408376964,
      "grad_norm": 1.1896488666534424,
      "learning_rate": 1.598603839441536e-05,
      "loss": 1.0061,
      "step": 2300
    },
    {
      "epoch": 0.6151832460732984,
      "grad_norm": 0.961165189743042,
      "learning_rate": 1.5898778359511345e-05,
      "loss": 1.0104,
      "step": 2350
    },
    {
      "epoch": 0.6282722513089005,
      "grad_norm": 1.0108668804168701,
      "learning_rate": 1.581151832460733e-05,
      "loss": 1.0076,
      "step": 2400
    },
    {
      "epoch": 0.6413612565445026,
      "grad_norm": 0.8675951361656189,
      "learning_rate": 1.572425828970332e-05,
      "loss": 0.9944,
      "step": 2450
    },
    {
      "epoch": 0.6544502617801047,
      "grad_norm": 1.4629746675491333,
      "learning_rate": 1.5636998254799302e-05,
      "loss": 0.9923,
      "step": 2500
    },
    {
      "epoch": 0.6675392670157068,
      "grad_norm": 0.8532177209854126,
      "learning_rate": 1.554973821989529e-05,
      "loss": 0.9868,
      "step": 2550
    },
    {
      "epoch": 0.680628272251309,
      "grad_norm": 1.1253283023834229,
      "learning_rate": 1.5462478184991274e-05,
      "loss": 0.9736,
      "step": 2600
    },
    {
      "epoch": 0.693717277486911,
      "grad_norm": 1.020376205444336,
      "learning_rate": 1.537521815008726e-05,
      "loss": 0.9994,
      "step": 2650
    },
    {
      "epoch": 0.7068062827225131,
      "grad_norm": 1.0807418823242188,
      "learning_rate": 1.528795811518325e-05,
      "loss": 0.9913,
      "step": 2700
    },
    {
      "epoch": 0.7198952879581152,
      "grad_norm": 1.0435155630111694,
      "learning_rate": 1.5200698080279233e-05,
      "loss": 0.9905,
      "step": 2750
    },
    {
      "epoch": 0.7329842931937173,
      "grad_norm": 1.7948681116104126,
      "learning_rate": 1.511343804537522e-05,
      "loss": 0.9823,
      "step": 2800
    },
    {
      "epoch": 0.7460732984293194,
      "grad_norm": 1.1531685590744019,
      "learning_rate": 1.5026178010471206e-05,
      "loss": 1.0055,
      "step": 2850
    },
    {
      "epoch": 0.7591623036649214,
      "grad_norm": 1.145842432975769,
      "learning_rate": 1.493891797556719e-05,
      "loss": 0.9838,
      "step": 2900
    },
    {
      "epoch": 0.7722513089005235,
      "grad_norm": 1.5351519584655762,
      "learning_rate": 1.4851657940663178e-05,
      "loss": 0.9758,
      "step": 2950
    },
    {
      "epoch": 0.7853403141361257,
      "grad_norm": 1.4190806150436401,
      "learning_rate": 1.4764397905759162e-05,
      "loss": 0.975,
      "step": 3000
    },
    {
      "epoch": 0.7984293193717278,
      "grad_norm": 1.2193337678909302,
      "learning_rate": 1.467713787085515e-05,
      "loss": 0.9827,
      "step": 3050
    },
    {
      "epoch": 0.8115183246073299,
      "grad_norm": 1.4238009452819824,
      "learning_rate": 1.4589877835951137e-05,
      "loss": 0.9653,
      "step": 3100
    },
    {
      "epoch": 0.824607329842932,
      "grad_norm": 1.4011480808258057,
      "learning_rate": 1.450261780104712e-05,
      "loss": 0.9684,
      "step": 3150
    },
    {
      "epoch": 0.837696335078534,
      "grad_norm": 1.377386450767517,
      "learning_rate": 1.4415357766143108e-05,
      "loss": 0.9633,
      "step": 3200
    },
    {
      "epoch": 0.8507853403141361,
      "grad_norm": 1.2685871124267578,
      "learning_rate": 1.4328097731239094e-05,
      "loss": 0.9677,
      "step": 3250
    },
    {
      "epoch": 0.8638743455497382,
      "grad_norm": 1.1994205713272095,
      "learning_rate": 1.424083769633508e-05,
      "loss": 0.936,
      "step": 3300
    },
    {
      "epoch": 0.8769633507853403,
      "grad_norm": 1.790286660194397,
      "learning_rate": 1.4153577661431066e-05,
      "loss": 0.9305,
      "step": 3350
    },
    {
      "epoch": 0.8900523560209425,
      "grad_norm": 1.3403974771499634,
      "learning_rate": 1.4066317626527052e-05,
      "loss": 0.9515,
      "step": 3400
    },
    {
      "epoch": 0.9031413612565445,
      "grad_norm": 2.375913143157959,
      "learning_rate": 1.3979057591623037e-05,
      "loss": 0.9509,
      "step": 3450
    },
    {
      "epoch": 0.9162303664921466,
      "grad_norm": 0.9907230138778687,
      "learning_rate": 1.3891797556719025e-05,
      "loss": 0.9464,
      "step": 3500
    },
    {
      "epoch": 0.9293193717277487,
      "grad_norm": 1.592445969581604,
      "learning_rate": 1.3804537521815009e-05,
      "loss": 0.9079,
      "step": 3550
    },
    {
      "epoch": 0.9424083769633508,
      "grad_norm": 3.7179832458496094,
      "learning_rate": 1.3717277486910996e-05,
      "loss": 0.9154,
      "step": 3600
    },
    {
      "epoch": 0.9554973821989529,
      "grad_norm": 2.043839693069458,
      "learning_rate": 1.3630017452006982e-05,
      "loss": 0.938,
      "step": 3650
    },
    {
      "epoch": 0.9685863874345549,
      "grad_norm": 3.0130717754364014,
      "learning_rate": 1.3542757417102968e-05,
      "loss": 0.9287,
      "step": 3700
    },
    {
      "epoch": 0.981675392670157,
      "grad_norm": 2.521247386932373,
      "learning_rate": 1.3455497382198954e-05,
      "loss": 0.9146,
      "step": 3750
    },
    {
      "epoch": 0.9947643979057592,
      "grad_norm": 2.3346762657165527,
      "learning_rate": 1.336823734729494e-05,
      "loss": 0.9318,
      "step": 3800
    },
    {
      "epoch": 1.0,
      "eval_runtime": 3.4472,
      "eval_samples_per_second": 240.193,
      "eval_steps_per_second": 15.085,
      "step": 3820
    },
    {
      "epoch": 1.0078534031413613,
      "grad_norm": 1.278563141822815,
      "learning_rate": 1.3280977312390925e-05,
      "loss": 0.9088,
      "step": 3850
    },
    {
      "epoch": 1.0209424083769634,
      "grad_norm": 2.8277533054351807,
      "learning_rate": 1.3193717277486913e-05,
      "loss": 0.9269,
      "step": 3900
    },
    {
      "epoch": 1.0340314136125655,
      "grad_norm": 1.1904146671295166,
      "learning_rate": 1.3106457242582897e-05,
      "loss": 0.9147,
      "step": 3950
    },
    {
      "epoch": 1.0471204188481675,
      "grad_norm": 2.471531391143799,
      "learning_rate": 1.3019197207678885e-05,
      "loss": 0.9189,
      "step": 4000
    },
    {
      "epoch": 1.0602094240837696,
      "grad_norm": 1.571066975593567,
      "learning_rate": 1.293193717277487e-05,
      "loss": 0.8988,
      "step": 4050
    },
    {
      "epoch": 1.0732984293193717,
      "grad_norm": 1.5904109477996826,
      "learning_rate": 1.2844677137870856e-05,
      "loss": 0.8969,
      "step": 4100
    },
    {
      "epoch": 1.0863874345549738,
      "grad_norm": 5.1125359535217285,
      "learning_rate": 1.2757417102966842e-05,
      "loss": 0.9009,
      "step": 4150
    },
    {
      "epoch": 1.0994764397905759,
      "grad_norm": 1.8844205141067505,
      "learning_rate": 1.2670157068062828e-05,
      "loss": 0.8821,
      "step": 4200
    },
    {
      "epoch": 1.112565445026178,
      "grad_norm": 3.275470733642578,
      "learning_rate": 1.2582897033158814e-05,
      "loss": 0.8831,
      "step": 4250
    },
    {
      "epoch": 1.12565445026178,
      "grad_norm": 1.445709228515625,
      "learning_rate": 1.2495636998254801e-05,
      "loss": 0.9004,
      "step": 4300
    },
    {
      "epoch": 1.1387434554973823,
      "grad_norm": 1.8207932710647583,
      "learning_rate": 1.2408376963350785e-05,
      "loss": 0.8989,
      "step": 4350
    },
    {
      "epoch": 1.1518324607329844,
      "grad_norm": 2.161489725112915,
      "learning_rate": 1.2321116928446773e-05,
      "loss": 0.8937,
      "step": 4400
    },
    {
      "epoch": 1.1649214659685865,
      "grad_norm": 1.6832765340805054,
      "learning_rate": 1.2233856893542758e-05,
      "loss": 0.8797,
      "step": 4450
    },
    {
      "epoch": 1.1780104712041886,
      "grad_norm": 1.9004144668579102,
      "learning_rate": 1.2146596858638744e-05,
      "loss": 0.8872,
      "step": 4500
    },
    {
      "epoch": 1.1910994764397906,
      "grad_norm": 1.269290804862976,
      "learning_rate": 1.205933682373473e-05,
      "loss": 0.86,
      "step": 4550
    },
    {
      "epoch": 1.2041884816753927,
      "grad_norm": 2.7547767162323,
      "learning_rate": 1.1972076788830716e-05,
      "loss": 0.8653,
      "step": 4600
    },
    {
      "epoch": 1.2172774869109948,
      "grad_norm": 1.952684998512268,
      "learning_rate": 1.1884816753926702e-05,
      "loss": 0.8747,
      "step": 4650
    },
    {
      "epoch": 1.2303664921465969,
      "grad_norm": 1.991668701171875,
      "learning_rate": 1.179755671902269e-05,
      "loss": 0.8562,
      "step": 4700
    },
    {
      "epoch": 1.243455497382199,
      "grad_norm": 1.5376319885253906,
      "learning_rate": 1.1710296684118673e-05,
      "loss": 0.8656,
      "step": 4750
    },
    {
      "epoch": 1.256544502617801,
      "grad_norm": 2.932345390319824,
      "learning_rate": 1.162303664921466e-05,
      "loss": 0.8534,
      "step": 4800
    },
    {
      "epoch": 1.2696335078534031,
      "grad_norm": 2.0792076587677,
      "learning_rate": 1.1535776614310648e-05,
      "loss": 0.8879,
      "step": 4850
    },
    {
      "epoch": 1.2827225130890052,
      "grad_norm": 1.5170563459396362,
      "learning_rate": 1.1448516579406632e-05,
      "loss": 0.8644,
      "step": 4900
    },
    {
      "epoch": 1.2958115183246073,
      "grad_norm": 1.7789674997329712,
      "learning_rate": 1.1361256544502618e-05,
      "loss": 0.8812,
      "step": 4950
    },
    {
      "epoch": 1.3089005235602094,
      "grad_norm": 1.3850574493408203,
      "learning_rate": 1.1273996509598604e-05,
      "loss": 0.8447,
      "step": 5000
    },
    {
      "epoch": 1.3219895287958114,
      "grad_norm": 2.3683114051818848,
      "learning_rate": 1.118673647469459e-05,
      "loss": 0.8684,
      "step": 5050
    },
    {
      "epoch": 1.3350785340314135,
      "grad_norm": 2.9799916744232178,
      "learning_rate": 1.1099476439790577e-05,
      "loss": 0.84,
      "step": 5100
    },
    {
      "epoch": 1.3481675392670156,
      "grad_norm": 2.7161073684692383,
      "learning_rate": 1.1012216404886561e-05,
      "loss": 0.8847,
      "step": 5150
    },
    {
      "epoch": 1.3612565445026177,
      "grad_norm": 1.4847365617752075,
      "learning_rate": 1.0924956369982549e-05,
      "loss": 0.8571,
      "step": 5200
    },
    {
      "epoch": 1.3743455497382198,
      "grad_norm": 2.839188814163208,
      "learning_rate": 1.0837696335078536e-05,
      "loss": 0.8784,
      "step": 5250
    },
    {
      "epoch": 1.387434554973822,
      "grad_norm": 1.9900130033493042,
      "learning_rate": 1.075043630017452e-05,
      "loss": 0.8856,
      "step": 5300
    },
    {
      "epoch": 1.4005235602094241,
      "grad_norm": 2.473986864089966,
      "learning_rate": 1.0663176265270508e-05,
      "loss": 0.8678,
      "step": 5350
    },
    {
      "epoch": 1.4136125654450262,
      "grad_norm": 1.6810969114303589,
      "learning_rate": 1.0575916230366492e-05,
      "loss": 0.8178,
      "step": 5400
    },
    {
      "epoch": 1.4267015706806283,
      "grad_norm": 2.233835220336914,
      "learning_rate": 1.048865619546248e-05,
      "loss": 0.851,
      "step": 5450
    },
    {
      "epoch": 1.4397905759162304,
      "grad_norm": 2.5557408332824707,
      "learning_rate": 1.0401396160558465e-05,
      "loss": 0.8732,
      "step": 5500
    },
    {
      "epoch": 1.4528795811518325,
      "grad_norm": 5.833676815032959,
      "learning_rate": 1.031413612565445e-05,
      "loss": 0.8409,
      "step": 5550
    },
    {
      "epoch": 1.4659685863874345,
      "grad_norm": 2.601451873779297,
      "learning_rate": 1.0226876090750437e-05,
      "loss": 0.8331,
      "step": 5600
    },
    {
      "epoch": 1.4790575916230366,
      "grad_norm": 3.5005624294281006,
      "learning_rate": 1.0139616055846425e-05,
      "loss": 0.8641,
      "step": 5650
    },
    {
      "epoch": 1.4921465968586387,
      "grad_norm": 2.9986345767974854,
      "learning_rate": 1.0052356020942409e-05,
      "loss": 0.8482,
      "step": 5700
    },
    {
      "epoch": 1.5052356020942408,
      "grad_norm": 2.3536689281463623,
      "learning_rate": 9.965095986038396e-06,
      "loss": 0.8547,
      "step": 5750
    },
    {
      "epoch": 1.518324607329843,
      "grad_norm": 2.80464506149292,
      "learning_rate": 9.877835951134382e-06,
      "loss": 0.8588,
      "step": 5800
    },
    {
      "epoch": 1.5314136125654452,
      "grad_norm": 1.7286456823349,
      "learning_rate": 9.790575916230368e-06,
      "loss": 0.8368,
      "step": 5850
    },
    {
      "epoch": 1.5445026178010473,
      "grad_norm": 1.5580425262451172,
      "learning_rate": 9.703315881326354e-06,
      "loss": 0.8196,
      "step": 5900
    },
    {
      "epoch": 1.5575916230366493,
      "grad_norm": 1.7789636850357056,
      "learning_rate": 9.61605584642234e-06,
      "loss": 0.8349,
      "step": 5950
    },
    {
      "epoch": 1.5706806282722514,
      "grad_norm": 1.811590313911438,
      "learning_rate": 9.528795811518325e-06,
      "loss": 0.829,
      "step": 6000
    },
    {
      "epoch": 1.5837696335078535,
      "grad_norm": 1.9018819332122803,
      "learning_rate": 9.441535776614311e-06,
      "loss": 0.8357,
      "step": 6050
    },
    {
      "epoch": 1.5968586387434556,
      "grad_norm": 2.4238710403442383,
      "learning_rate": 9.354275741710297e-06,
      "loss": 0.8117,
      "step": 6100
    },
    {
      "epoch": 1.6099476439790577,
      "grad_norm": 2.7017602920532227,
      "learning_rate": 9.267015706806284e-06,
      "loss": 0.818,
      "step": 6150
    },
    {
      "epoch": 1.6230366492146597,
      "grad_norm": 3.9329402446746826,
      "learning_rate": 9.17975567190227e-06,
      "loss": 0.8328,
      "step": 6200
    },
    {
      "epoch": 1.6361256544502618,
      "grad_norm": 2.346749782562256,
      "learning_rate": 9.092495636998256e-06,
      "loss": 0.8399,
      "step": 6250
    },
    {
      "epoch": 1.649214659685864,
      "grad_norm": 1.5601551532745361,
      "learning_rate": 9.005235602094242e-06,
      "loss": 0.8556,
      "step": 6300
    },
    {
      "epoch": 1.662303664921466,
      "grad_norm": 1.8609222173690796,
      "learning_rate": 8.917975567190227e-06,
      "loss": 0.8348,
      "step": 6350
    },
    {
      "epoch": 1.675392670157068,
      "grad_norm": 3.75785756111145,
      "learning_rate": 8.830715532286213e-06,
      "loss": 0.8509,
      "step": 6400
    },
    {
      "epoch": 1.6884816753926701,
      "grad_norm": 2.0949692726135254,
      "learning_rate": 8.743455497382199e-06,
      "loss": 0.7867,
      "step": 6450
    },
    {
      "epoch": 1.7015706806282722,
      "grad_norm": 4.460891246795654,
      "learning_rate": 8.656195462478185e-06,
      "loss": 0.8419,
      "step": 6500
    },
    {
      "epoch": 1.7146596858638743,
      "grad_norm": 2.6954312324523926,
      "learning_rate": 8.568935427574172e-06,
      "loss": 0.8226,
      "step": 6550
    },
    {
      "epoch": 1.7277486910994764,
      "grad_norm": 1.2572908401489258,
      "learning_rate": 8.481675392670158e-06,
      "loss": 0.8329,
      "step": 6600
    },
    {
      "epoch": 1.7408376963350785,
      "grad_norm": 3.1700851917266846,
      "learning_rate": 8.394415357766144e-06,
      "loss": 0.8211,
      "step": 6650
    },
    {
      "epoch": 1.7539267015706805,
      "grad_norm": 1.8860417604446411,
      "learning_rate": 8.30715532286213e-06,
      "loss": 0.8611,
      "step": 6700
    },
    {
      "epoch": 1.7670157068062826,
      "grad_norm": 3.394249200820923,
      "learning_rate": 8.219895287958116e-06,
      "loss": 0.8092,
      "step": 6750
    },
    {
      "epoch": 1.7801047120418847,
      "grad_norm": 2.0876073837280273,
      "learning_rate": 8.132635253054101e-06,
      "loss": 0.8361,
      "step": 6800
    },
    {
      "epoch": 1.7931937172774868,
      "grad_norm": 3.4384775161743164,
      "learning_rate": 8.045375218150087e-06,
      "loss": 0.8168,
      "step": 6850
    },
    {
      "epoch": 1.8062827225130889,
      "grad_norm": 3.864570140838623,
      "learning_rate": 7.958115183246073e-06,
      "loss": 0.8263,
      "step": 6900
    },
    {
      "epoch": 1.819371727748691,
      "grad_norm": 3.4430465698242188,
      "learning_rate": 7.87085514834206e-06,
      "loss": 0.8251,
      "step": 6950
    },
    {
      "epoch": 1.8324607329842932,
      "grad_norm": 2.7167351245880127,
      "learning_rate": 7.783595113438046e-06,
      "loss": 0.841,
      "step": 7000
    },
    {
      "epoch": 1.8455497382198953,
      "grad_norm": 2.401614189147949,
      "learning_rate": 7.696335078534032e-06,
      "loss": 0.8025,
      "step": 7050
    },
    {
      "epoch": 1.8586387434554974,
      "grad_norm": 2.185201406478882,
      "learning_rate": 7.609075043630018e-06,
      "loss": 0.817,
      "step": 7100
    },
    {
      "epoch": 1.8717277486910995,
      "grad_norm": 2.4319300651550293,
      "learning_rate": 7.521815008726005e-06,
      "loss": 0.7985,
      "step": 7150
    },
    {
      "epoch": 1.8848167539267016,
      "grad_norm": 2.741758108139038,
      "learning_rate": 7.43455497382199e-06,
      "loss": 0.8359,
      "step": 7200
    },
    {
      "epoch": 1.8979057591623036,
      "grad_norm": 2.0391652584075928,
      "learning_rate": 7.347294938917976e-06,
      "loss": 0.8138,
      "step": 7250
    },
    {
      "epoch": 1.9109947643979057,
      "grad_norm": 2.750030755996704,
      "learning_rate": 7.260034904013962e-06,
      "loss": 0.8224,
      "step": 7300
    },
    {
      "epoch": 1.9240837696335078,
      "grad_norm": 2.1241908073425293,
      "learning_rate": 7.172774869109949e-06,
      "loss": 0.8294,
      "step": 7350
    },
    {
      "epoch": 1.93717277486911,
      "grad_norm": 2.8487730026245117,
      "learning_rate": 7.0855148342059345e-06,
      "loss": 0.8399,
      "step": 7400
    },
    {
      "epoch": 1.9502617801047122,
      "grad_norm": 4.371936321258545,
      "learning_rate": 6.99825479930192e-06,
      "loss": 0.8313,
      "step": 7450
    },
    {
      "epoch": 1.9633507853403143,
      "grad_norm": 1.942654013633728,
      "learning_rate": 6.910994764397906e-06,
      "loss": 0.8241,
      "step": 7500
    },
    {
      "epoch": 1.9764397905759163,
      "grad_norm": 2.255502462387085,
      "learning_rate": 6.823734729493893e-06,
      "loss": 0.8423,
      "step": 7550
    },
    {
      "epoch": 1.9895287958115184,
      "grad_norm": 2.0910708904266357,
      "learning_rate": 6.7364746945898785e-06,
      "loss": 0.7993,
      "step": 7600
    },
    {
      "epoch": 2.0,
      "eval_runtime": 3.01,
      "eval_samples_per_second": 275.084,
      "eval_steps_per_second": 17.276,
      "step": 7640
    },
    {
      "epoch": 2.0026178010471205,
      "grad_norm": 2.8479506969451904,
      "learning_rate": 6.649214659685864e-06,
      "loss": 0.8112,
      "step": 7650
    },
    {
      "epoch": 2.0157068062827226,
      "grad_norm": 4.296245098114014,
      "learning_rate": 6.56195462478185e-06,
      "loss": 0.8078,
      "step": 7700
    },
    {
      "epoch": 2.0287958115183247,
      "grad_norm": 2.477992296218872,
      "learning_rate": 6.474694589877837e-06,
      "loss": 0.814,
      "step": 7750
    },
    {
      "epoch": 2.0418848167539267,
      "grad_norm": 3.7627463340759277,
      "learning_rate": 6.3874345549738226e-06,
      "loss": 0.833,
      "step": 7800
    },
    {
      "epoch": 2.054973821989529,
      "grad_norm": 4.368931770324707,
      "learning_rate": 6.300174520069808e-06,
      "loss": 0.8278,
      "step": 7850
    },
    {
      "epoch": 2.068062827225131,
      "grad_norm": 2.7245304584503174,
      "learning_rate": 6.212914485165794e-06,
      "loss": 0.8175,
      "step": 7900
    },
    {
      "epoch": 2.081151832460733,
      "grad_norm": 2.02795147895813,
      "learning_rate": 6.125654450261781e-06,
      "loss": 0.8309,
      "step": 7950
    },
    {
      "epoch": 2.094240837696335,
      "grad_norm": 3.2018089294433594,
      "learning_rate": 6.038394415357767e-06,
      "loss": 0.8259,
      "step": 8000
    },
    {
      "epoch": 2.107329842931937,
      "grad_norm": 3.6144073009490967,
      "learning_rate": 5.9511343804537524e-06,
      "loss": 0.8317,
      "step": 8050
    },
    {
      "epoch": 2.1204188481675392,
      "grad_norm": 2.802166223526001,
      "learning_rate": 5.863874345549738e-06,
      "loss": 0.8187,
      "step": 8100
    },
    {
      "epoch": 2.1335078534031413,
      "grad_norm": 3.804755687713623,
      "learning_rate": 5.776614310645725e-06,
      "loss": 0.8086,
      "step": 8150
    },
    {
      "epoch": 2.1465968586387434,
      "grad_norm": 3.8666980266571045,
      "learning_rate": 5.689354275741711e-06,
      "loss": 0.832,
      "step": 8200
    },
    {
      "epoch": 2.1596858638743455,
      "grad_norm": 2.6105356216430664,
      "learning_rate": 5.6020942408376965e-06,
      "loss": 0.8056,
      "step": 8250
    },
    {
      "epoch": 2.1727748691099475,
      "grad_norm": 3.0874900817871094,
      "learning_rate": 5.514834205933682e-06,
      "loss": 0.8016,
      "step": 8300
    },
    {
      "epoch": 2.1858638743455496,
      "grad_norm": 3.5247902870178223,
      "learning_rate": 5.427574171029669e-06,
      "loss": 0.7763,
      "step": 8350
    },
    {
      "epoch": 2.1989528795811517,
      "grad_norm": 2.0883686542510986,
      "learning_rate": 5.340314136125655e-06,
      "loss": 0.8277,
      "step": 8400
    },
    {
      "epoch": 2.212041884816754,
      "grad_norm": 3.1585426330566406,
      "learning_rate": 5.2530541012216406e-06,
      "loss": 0.8197,
      "step": 8450
    },
    {
      "epoch": 2.225130890052356,
      "grad_norm": 2.2767786979675293,
      "learning_rate": 5.165794066317626e-06,
      "loss": 0.8189,
      "step": 8500
    },
    {
      "epoch": 2.238219895287958,
      "grad_norm": 4.294629096984863,
      "learning_rate": 5.078534031413613e-06,
      "loss": 0.8183,
      "step": 8550
    },
    {
      "epoch": 2.25130890052356,
      "grad_norm": 3.213367223739624,
      "learning_rate": 4.991273996509599e-06,
      "loss": 0.8183,
      "step": 8600
    },
    {
      "epoch": 2.264397905759162,
      "grad_norm": 3.7709157466888428,
      "learning_rate": 4.904013961605585e-06,
      "loss": 0.8335,
      "step": 8650
    },
    {
      "epoch": 2.2774869109947646,
      "grad_norm": 2.556166648864746,
      "learning_rate": 4.816753926701571e-06,
      "loss": 0.7952,
      "step": 8700
    },
    {
      "epoch": 2.2905759162303667,
      "grad_norm": 4.05082893371582,
      "learning_rate": 4.729493891797557e-06,
      "loss": 0.8036,
      "step": 8750
    },
    {
      "epoch": 2.303664921465969,
      "grad_norm": 2.862699508666992,
      "learning_rate": 4.642233856893543e-06,
      "loss": 0.8322,
      "step": 8800
    },
    {
      "epoch": 2.316753926701571,
      "grad_norm": 2.42250919342041,
      "learning_rate": 4.554973821989529e-06,
      "loss": 0.7853,
      "step": 8850
    },
    {
      "epoch": 2.329842931937173,
      "grad_norm": 3.036316156387329,
      "learning_rate": 4.467713787085515e-06,
      "loss": 0.7707,
      "step": 8900
    },
    {
      "epoch": 2.342931937172775,
      "grad_norm": 4.120965003967285,
      "learning_rate": 4.380453752181501e-06,
      "loss": 0.8353,
      "step": 8950
    },
    {
      "epoch": 2.356020942408377,
      "grad_norm": 1.6152575016021729,
      "learning_rate": 4.293193717277487e-06,
      "loss": 0.8316,
      "step": 9000
    },
    {
      "epoch": 2.369109947643979,
      "grad_norm": 2.209139108657837,
      "learning_rate": 4.205933682373473e-06,
      "loss": 0.7965,
      "step": 9050
    },
    {
      "epoch": 2.3821989528795813,
      "grad_norm": 2.2695140838623047,
      "learning_rate": 4.118673647469459e-06,
      "loss": 0.8,
      "step": 9100
    },
    {
      "epoch": 2.3952879581151834,
      "grad_norm": 4.236510276794434,
      "learning_rate": 4.031413612565445e-06,
      "loss": 0.7989,
      "step": 9150
    },
    {
      "epoch": 2.4083769633507854,
      "grad_norm": 1.6595261096954346,
      "learning_rate": 3.944153577661432e-06,
      "loss": 0.7902,
      "step": 9200
    },
    {
      "epoch": 2.4214659685863875,
      "grad_norm": 4.348808765411377,
      "learning_rate": 3.856893542757417e-06,
      "loss": 0.7841,
      "step": 9250
    },
    {
      "epoch": 2.4345549738219896,
      "grad_norm": 4.372086048126221,
      "learning_rate": 3.7696335078534035e-06,
      "loss": 0.7812,
      "step": 9300
    },
    {
      "epoch": 2.4476439790575917,
      "grad_norm": 5.081228733062744,
      "learning_rate": 3.6823734729493893e-06,
      "loss": 0.8096,
      "step": 9350
    },
    {
      "epoch": 2.4607329842931938,
      "grad_norm": 3.80869460105896,
      "learning_rate": 3.5951134380453755e-06,
      "loss": 0.8496,
      "step": 9400
    },
    {
      "epoch": 2.473821989528796,
      "grad_norm": 3.4352970123291016,
      "learning_rate": 3.5078534031413613e-06,
      "loss": 0.8099,
      "step": 9450
    },
    {
      "epoch": 2.486910994764398,
      "grad_norm": 2.300075054168701,
      "learning_rate": 3.4205933682373475e-06,
      "loss": 0.8161,
      "step": 9500
    },
    {
      "epoch": 2.5,
      "grad_norm": 2.88323712348938,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 0.7944,
      "step": 9550
    },
    {
      "epoch": 2.513089005235602,
      "grad_norm": 2.6522154808044434,
      "learning_rate": 3.2460732984293196e-06,
      "loss": 0.8064,
      "step": 9600
    },
    {
      "epoch": 2.526178010471204,
      "grad_norm": 3.7529640197753906,
      "learning_rate": 3.1588132635253054e-06,
      "loss": 0.8087,
      "step": 9650
    },
    {
      "epoch": 2.5392670157068062,
      "grad_norm": 1.2546982765197754,
      "learning_rate": 3.071553228621292e-06,
      "loss": 0.8012,
      "step": 9700
    },
    {
      "epoch": 2.5523560209424083,
      "grad_norm": 2.93544864654541,
      "learning_rate": 2.9842931937172774e-06,
      "loss": 0.7924,
      "step": 9750
    },
    {
      "epoch": 2.5654450261780104,
      "grad_norm": 3.009612798690796,
      "learning_rate": 2.897033158813264e-06,
      "loss": 0.8103,
      "step": 9800
    },
    {
      "epoch": 2.5785340314136125,
      "grad_norm": 2.75213360786438,
      "learning_rate": 2.8097731239092494e-06,
      "loss": 0.7922,
      "step": 9850
    },
    {
      "epoch": 2.5916230366492146,
      "grad_norm": 3.6011593341827393,
      "learning_rate": 2.722513089005236e-06,
      "loss": 0.7917,
      "step": 9900
    },
    {
      "epoch": 2.6047120418848166,
      "grad_norm": 1.9084248542785645,
      "learning_rate": 2.635253054101222e-06,
      "loss": 0.8065,
      "step": 9950
    },
    {
      "epoch": 2.6178010471204187,
      "grad_norm": 2.501206636428833,
      "learning_rate": 2.547993019197208e-06,
      "loss": 0.8231,
      "step": 10000
    },
    {
      "epoch": 2.630890052356021,
      "grad_norm": 2.627959966659546,
      "learning_rate": 2.460732984293194e-06,
      "loss": 0.8135,
      "step": 10050
    },
    {
      "epoch": 2.643979057591623,
      "grad_norm": 3.676687002182007,
      "learning_rate": 2.37347294938918e-06,
      "loss": 0.795,
      "step": 10100
    },
    {
      "epoch": 2.657068062827225,
      "grad_norm": 2.450251817703247,
      "learning_rate": 2.286212914485166e-06,
      "loss": 0.7727,
      "step": 10150
    },
    {
      "epoch": 2.670157068062827,
      "grad_norm": 3.5001299381256104,
      "learning_rate": 2.198952879581152e-06,
      "loss": 0.8233,
      "step": 10200
    },
    {
      "epoch": 2.683246073298429,
      "grad_norm": 2.849515199661255,
      "learning_rate": 2.111692844677138e-06,
      "loss": 0.8005,
      "step": 10250
    },
    {
      "epoch": 2.696335078534031,
      "grad_norm": 3.5205678939819336,
      "learning_rate": 2.024432809773124e-06,
      "loss": 0.7851,
      "step": 10300
    },
    {
      "epoch": 2.7094240837696333,
      "grad_norm": 3.57798433303833,
      "learning_rate": 1.9371727748691104e-06,
      "loss": 0.8093,
      "step": 10350
    },
    {
      "epoch": 2.7225130890052354,
      "grad_norm": 3.1891350746154785,
      "learning_rate": 1.8499127399650962e-06,
      "loss": 0.7692,
      "step": 10400
    },
    {
      "epoch": 2.7356020942408374,
      "grad_norm": 2.8894412517547607,
      "learning_rate": 1.7626527050610822e-06,
      "loss": 0.8254,
      "step": 10450
    },
    {
      "epoch": 2.7486910994764395,
      "grad_norm": 1.537166714668274,
      "learning_rate": 1.6753926701570683e-06,
      "loss": 0.8073,
      "step": 10500
    },
    {
      "epoch": 2.761780104712042,
      "grad_norm": 3.4750237464904785,
      "learning_rate": 1.5881326352530543e-06,
      "loss": 0.8282,
      "step": 10550
    },
    {
      "epoch": 2.774869109947644,
      "grad_norm": 2.8850045204162598,
      "learning_rate": 1.5008726003490403e-06,
      "loss": 0.7787,
      "step": 10600
    },
    {
      "epoch": 2.787958115183246,
      "grad_norm": 2.991783857345581,
      "learning_rate": 1.4136125654450263e-06,
      "loss": 0.8168,
      "step": 10650
    },
    {
      "epoch": 2.8010471204188483,
      "grad_norm": 2.3828587532043457,
      "learning_rate": 1.3263525305410125e-06,
      "loss": 0.764,
      "step": 10700
    },
    {
      "epoch": 2.8141361256544504,
      "grad_norm": 4.874160289764404,
      "learning_rate": 1.2390924956369983e-06,
      "loss": 0.8145,
      "step": 10750
    },
    {
      "epoch": 2.8272251308900525,
      "grad_norm": 2.727910041809082,
      "learning_rate": 1.1518324607329843e-06,
      "loss": 0.8072,
      "step": 10800
    },
    {
      "epoch": 2.8403141361256545,
      "grad_norm": 3.029592990875244,
      "learning_rate": 1.0645724258289704e-06,
      "loss": 0.7947,
      "step": 10850
    },
    {
      "epoch": 2.8534031413612566,
      "grad_norm": 2.2432241439819336,
      "learning_rate": 9.773123909249564e-07,
      "loss": 0.7946,
      "step": 10900
    },
    {
      "epoch": 2.8664921465968587,
      "grad_norm": 2.199408531188965,
      "learning_rate": 8.900523560209425e-07,
      "loss": 0.808,
      "step": 10950
    },
    {
      "epoch": 2.8795811518324608,
      "grad_norm": 2.5183663368225098,
      "learning_rate": 8.027923211169285e-07,
      "loss": 0.7844,
      "step": 11000
    },
    {
      "epoch": 2.892670157068063,
      "grad_norm": 1.9854627847671509,
      "learning_rate": 7.155322862129145e-07,
      "loss": 0.7921,
      "step": 11050
    },
    {
      "epoch": 2.905759162303665,
      "grad_norm": 3.7920210361480713,
      "learning_rate": 6.282722513089005e-07,
      "loss": 0.8256,
      "step": 11100
    },
    {
      "epoch": 2.918848167539267,
      "grad_norm": 1.7648706436157227,
      "learning_rate": 5.410122164048866e-07,
      "loss": 0.8207,
      "step": 11150
    },
    {
      "epoch": 2.931937172774869,
      "grad_norm": 5.248110771179199,
      "learning_rate": 4.537521815008726e-07,
      "loss": 0.8026,
      "step": 11200
    },
    {
      "epoch": 2.945026178010471,
      "grad_norm": 2.4270331859588623,
      "learning_rate": 3.6649214659685864e-07,
      "loss": 0.764,
      "step": 11250
    },
    {
      "epoch": 2.9581151832460733,
      "grad_norm": 3.6709160804748535,
      "learning_rate": 2.792321116928447e-07,
      "loss": 0.7758,
      "step": 11300
    },
    {
      "epoch": 2.9712041884816753,
      "grad_norm": 4.529517650604248,
      "learning_rate": 1.9197207678883075e-07,
      "loss": 0.816,
      "step": 11350
    },
    {
      "epoch": 2.9842931937172774,
      "grad_norm": 3.085301160812378,
      "learning_rate": 1.0471204188481677e-07,
      "loss": 0.8219,
      "step": 11400
    },
    {
      "epoch": 2.9973821989528795,
      "grad_norm": 3.251500368118286,
      "learning_rate": 1.7452006980802794e-08,
      "loss": 0.7973,
      "step": 11450
    },
    {
      "epoch": 3.0,
      "eval_runtime": 2.9475,
      "eval_samples_per_second": 280.92,
      "eval_steps_per_second": 17.642,
      "step": 11460
    }
  ],
  "logging_steps": 50,
  "max_steps": 11460,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.210264871804928e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
