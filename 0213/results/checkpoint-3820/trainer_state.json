{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 3820,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.013089005235602094,
      "grad_norm": 0.12118277698755264,
      "learning_rate": 1.9912739965095987e-05,
      "loss": 1.115,
      "step": 50
    },
    {
      "epoch": 0.02617801047120419,
      "grad_norm": 0.17336107790470123,
      "learning_rate": 1.9825479930191973e-05,
      "loss": 1.1158,
      "step": 100
    },
    {
      "epoch": 0.03926701570680628,
      "grad_norm": 0.3817252516746521,
      "learning_rate": 1.973821989528796e-05,
      "loss": 1.1155,
      "step": 150
    },
    {
      "epoch": 0.05235602094240838,
      "grad_norm": 0.20205768942832947,
      "learning_rate": 1.9650959860383945e-05,
      "loss": 1.116,
      "step": 200
    },
    {
      "epoch": 0.06544502617801047,
      "grad_norm": 0.19136646389961243,
      "learning_rate": 1.956369982547993e-05,
      "loss": 1.0893,
      "step": 250
    },
    {
      "epoch": 0.07853403141361257,
      "grad_norm": 0.3084053099155426,
      "learning_rate": 1.947643979057592e-05,
      "loss": 1.0854,
      "step": 300
    },
    {
      "epoch": 0.09162303664921466,
      "grad_norm": 0.32901453971862793,
      "learning_rate": 1.9389179755671902e-05,
      "loss": 1.0923,
      "step": 350
    },
    {
      "epoch": 0.10471204188481675,
      "grad_norm": 0.32096418738365173,
      "learning_rate": 1.930191972076789e-05,
      "loss": 1.0846,
      "step": 400
    },
    {
      "epoch": 0.11780104712041885,
      "grad_norm": 0.3386801481246948,
      "learning_rate": 1.9214659685863877e-05,
      "loss": 1.084,
      "step": 450
    },
    {
      "epoch": 0.13089005235602094,
      "grad_norm": 0.46849507093429565,
      "learning_rate": 1.9127399650959863e-05,
      "loss": 1.0753,
      "step": 500
    },
    {
      "epoch": 0.14397905759162305,
      "grad_norm": 0.373625785112381,
      "learning_rate": 1.904013961605585e-05,
      "loss": 1.0676,
      "step": 550
    },
    {
      "epoch": 0.15706806282722513,
      "grad_norm": 0.6743139028549194,
      "learning_rate": 1.895287958115183e-05,
      "loss": 1.0772,
      "step": 600
    },
    {
      "epoch": 0.17015706806282724,
      "grad_norm": 0.506660521030426,
      "learning_rate": 1.886561954624782e-05,
      "loss": 1.0668,
      "step": 650
    },
    {
      "epoch": 0.18324607329842932,
      "grad_norm": 0.4669664800167084,
      "learning_rate": 1.8778359511343806e-05,
      "loss": 1.0579,
      "step": 700
    },
    {
      "epoch": 0.19633507853403143,
      "grad_norm": 1.4325381517410278,
      "learning_rate": 1.8691099476439792e-05,
      "loss": 1.0444,
      "step": 750
    },
    {
      "epoch": 0.2094240837696335,
      "grad_norm": 0.841909646987915,
      "learning_rate": 1.8603839441535778e-05,
      "loss": 1.0404,
      "step": 800
    },
    {
      "epoch": 0.22251308900523561,
      "grad_norm": 0.9710665941238403,
      "learning_rate": 1.8516579406631764e-05,
      "loss": 1.0468,
      "step": 850
    },
    {
      "epoch": 0.2356020942408377,
      "grad_norm": 0.4884214401245117,
      "learning_rate": 1.842931937172775e-05,
      "loss": 1.0239,
      "step": 900
    },
    {
      "epoch": 0.2486910994764398,
      "grad_norm": 1.8202688694000244,
      "learning_rate": 1.8342059336823735e-05,
      "loss": 1.0434,
      "step": 950
    },
    {
      "epoch": 0.2617801047120419,
      "grad_norm": 0.9531408548355103,
      "learning_rate": 1.825479930191972e-05,
      "loss": 1.0427,
      "step": 1000
    },
    {
      "epoch": 0.27486910994764396,
      "grad_norm": 0.487871915102005,
      "learning_rate": 1.8167539267015707e-05,
      "loss": 1.0428,
      "step": 1050
    },
    {
      "epoch": 0.2879581151832461,
      "grad_norm": 1.1555445194244385,
      "learning_rate": 1.8080279232111696e-05,
      "loss": 1.0366,
      "step": 1100
    },
    {
      "epoch": 0.3010471204188482,
      "grad_norm": 0.6162355542182922,
      "learning_rate": 1.799301919720768e-05,
      "loss": 1.0178,
      "step": 1150
    },
    {
      "epoch": 0.31413612565445026,
      "grad_norm": 0.6140527129173279,
      "learning_rate": 1.7905759162303668e-05,
      "loss": 1.0302,
      "step": 1200
    },
    {
      "epoch": 0.32722513089005234,
      "grad_norm": 0.6246379017829895,
      "learning_rate": 1.7818499127399654e-05,
      "loss": 1.0312,
      "step": 1250
    },
    {
      "epoch": 0.3403141361256545,
      "grad_norm": 0.7229703664779663,
      "learning_rate": 1.773123909249564e-05,
      "loss": 1.0313,
      "step": 1300
    },
    {
      "epoch": 0.35340314136125656,
      "grad_norm": 1.373700499534607,
      "learning_rate": 1.7643979057591625e-05,
      "loss": 1.0133,
      "step": 1350
    },
    {
      "epoch": 0.36649214659685864,
      "grad_norm": 0.9335792660713196,
      "learning_rate": 1.755671902268761e-05,
      "loss": 1.033,
      "step": 1400
    },
    {
      "epoch": 0.3795811518324607,
      "grad_norm": 2.1842923164367676,
      "learning_rate": 1.7469458987783597e-05,
      "loss": 1.0192,
      "step": 1450
    },
    {
      "epoch": 0.39267015706806285,
      "grad_norm": 0.8742027282714844,
      "learning_rate": 1.7382198952879583e-05,
      "loss": 1.0349,
      "step": 1500
    },
    {
      "epoch": 0.40575916230366493,
      "grad_norm": 0.6279504895210266,
      "learning_rate": 1.729493891797557e-05,
      "loss": 1.0252,
      "step": 1550
    },
    {
      "epoch": 0.418848167539267,
      "grad_norm": 0.8896008729934692,
      "learning_rate": 1.7207678883071554e-05,
      "loss": 1.0386,
      "step": 1600
    },
    {
      "epoch": 0.4319371727748691,
      "grad_norm": 0.57406085729599,
      "learning_rate": 1.712041884816754e-05,
      "loss": 1.028,
      "step": 1650
    },
    {
      "epoch": 0.44502617801047123,
      "grad_norm": 0.6361834406852722,
      "learning_rate": 1.7033158813263526e-05,
      "loss": 1.0141,
      "step": 1700
    },
    {
      "epoch": 0.4581151832460733,
      "grad_norm": 0.49638131260871887,
      "learning_rate": 1.694589877835951e-05,
      "loss": 1.0103,
      "step": 1750
    },
    {
      "epoch": 0.4712041884816754,
      "grad_norm": 2.087602376937866,
      "learning_rate": 1.6858638743455497e-05,
      "loss": 1.0076,
      "step": 1800
    },
    {
      "epoch": 0.48429319371727747,
      "grad_norm": 0.8858644366264343,
      "learning_rate": 1.6771378708551483e-05,
      "loss": 1.0138,
      "step": 1850
    },
    {
      "epoch": 0.4973821989528796,
      "grad_norm": 0.9705279469490051,
      "learning_rate": 1.6684118673647472e-05,
      "loss": 1.0266,
      "step": 1900
    },
    {
      "epoch": 0.5104712041884817,
      "grad_norm": 0.9348119497299194,
      "learning_rate": 1.6596858638743455e-05,
      "loss": 1.0013,
      "step": 1950
    },
    {
      "epoch": 0.5235602094240838,
      "grad_norm": 0.8809092044830322,
      "learning_rate": 1.6509598603839444e-05,
      "loss": 1.0176,
      "step": 2000
    },
    {
      "epoch": 0.5366492146596858,
      "grad_norm": 0.9426864981651306,
      "learning_rate": 1.642233856893543e-05,
      "loss": 0.9743,
      "step": 2050
    },
    {
      "epoch": 0.5497382198952879,
      "grad_norm": 1.5908390283584595,
      "learning_rate": 1.6335078534031416e-05,
      "loss": 0.9934,
      "step": 2100
    },
    {
      "epoch": 0.56282722513089,
      "grad_norm": 0.6813254356384277,
      "learning_rate": 1.62478184991274e-05,
      "loss": 1.0186,
      "step": 2150
    },
    {
      "epoch": 0.5759162303664922,
      "grad_norm": 2.6370980739593506,
      "learning_rate": 1.6160558464223387e-05,
      "loss": 0.9976,
      "step": 2200
    },
    {
      "epoch": 0.5890052356020943,
      "grad_norm": 0.702314555644989,
      "learning_rate": 1.6073298429319373e-05,
      "loss": 1.0086,
      "step": 2250
    },
    {
      "epoch": 0.6020942408376964,
      "grad_norm": 1.1896488666534424,
      "learning_rate": 1.598603839441536e-05,
      "loss": 1.0061,
      "step": 2300
    },
    {
      "epoch": 0.6151832460732984,
      "grad_norm": 0.961165189743042,
      "learning_rate": 1.5898778359511345e-05,
      "loss": 1.0104,
      "step": 2350
    },
    {
      "epoch": 0.6282722513089005,
      "grad_norm": 1.0108668804168701,
      "learning_rate": 1.581151832460733e-05,
      "loss": 1.0076,
      "step": 2400
    },
    {
      "epoch": 0.6413612565445026,
      "grad_norm": 0.8675951361656189,
      "learning_rate": 1.572425828970332e-05,
      "loss": 0.9944,
      "step": 2450
    },
    {
      "epoch": 0.6544502617801047,
      "grad_norm": 1.4629746675491333,
      "learning_rate": 1.5636998254799302e-05,
      "loss": 0.9923,
      "step": 2500
    },
    {
      "epoch": 0.6675392670157068,
      "grad_norm": 0.8532177209854126,
      "learning_rate": 1.554973821989529e-05,
      "loss": 0.9868,
      "step": 2550
    },
    {
      "epoch": 0.680628272251309,
      "grad_norm": 1.1253283023834229,
      "learning_rate": 1.5462478184991274e-05,
      "loss": 0.9736,
      "step": 2600
    },
    {
      "epoch": 0.693717277486911,
      "grad_norm": 1.020376205444336,
      "learning_rate": 1.537521815008726e-05,
      "loss": 0.9994,
      "step": 2650
    },
    {
      "epoch": 0.7068062827225131,
      "grad_norm": 1.0807418823242188,
      "learning_rate": 1.528795811518325e-05,
      "loss": 0.9913,
      "step": 2700
    },
    {
      "epoch": 0.7198952879581152,
      "grad_norm": 1.0435155630111694,
      "learning_rate": 1.5200698080279233e-05,
      "loss": 0.9905,
      "step": 2750
    },
    {
      "epoch": 0.7329842931937173,
      "grad_norm": 1.7948681116104126,
      "learning_rate": 1.511343804537522e-05,
      "loss": 0.9823,
      "step": 2800
    },
    {
      "epoch": 0.7460732984293194,
      "grad_norm": 1.1531685590744019,
      "learning_rate": 1.5026178010471206e-05,
      "loss": 1.0055,
      "step": 2850
    },
    {
      "epoch": 0.7591623036649214,
      "grad_norm": 1.145842432975769,
      "learning_rate": 1.493891797556719e-05,
      "loss": 0.9838,
      "step": 2900
    },
    {
      "epoch": 0.7722513089005235,
      "grad_norm": 1.5351519584655762,
      "learning_rate": 1.4851657940663178e-05,
      "loss": 0.9758,
      "step": 2950
    },
    {
      "epoch": 0.7853403141361257,
      "grad_norm": 1.4190806150436401,
      "learning_rate": 1.4764397905759162e-05,
      "loss": 0.975,
      "step": 3000
    },
    {
      "epoch": 0.7984293193717278,
      "grad_norm": 1.2193337678909302,
      "learning_rate": 1.467713787085515e-05,
      "loss": 0.9827,
      "step": 3050
    },
    {
      "epoch": 0.8115183246073299,
      "grad_norm": 1.4238009452819824,
      "learning_rate": 1.4589877835951137e-05,
      "loss": 0.9653,
      "step": 3100
    },
    {
      "epoch": 0.824607329842932,
      "grad_norm": 1.4011480808258057,
      "learning_rate": 1.450261780104712e-05,
      "loss": 0.9684,
      "step": 3150
    },
    {
      "epoch": 0.837696335078534,
      "grad_norm": 1.377386450767517,
      "learning_rate": 1.4415357766143108e-05,
      "loss": 0.9633,
      "step": 3200
    },
    {
      "epoch": 0.8507853403141361,
      "grad_norm": 1.2685871124267578,
      "learning_rate": 1.4328097731239094e-05,
      "loss": 0.9677,
      "step": 3250
    },
    {
      "epoch": 0.8638743455497382,
      "grad_norm": 1.1994205713272095,
      "learning_rate": 1.424083769633508e-05,
      "loss": 0.936,
      "step": 3300
    },
    {
      "epoch": 0.8769633507853403,
      "grad_norm": 1.790286660194397,
      "learning_rate": 1.4153577661431066e-05,
      "loss": 0.9305,
      "step": 3350
    },
    {
      "epoch": 0.8900523560209425,
      "grad_norm": 1.3403974771499634,
      "learning_rate": 1.4066317626527052e-05,
      "loss": 0.9515,
      "step": 3400
    },
    {
      "epoch": 0.9031413612565445,
      "grad_norm": 2.375913143157959,
      "learning_rate": 1.3979057591623037e-05,
      "loss": 0.9509,
      "step": 3450
    },
    {
      "epoch": 0.9162303664921466,
      "grad_norm": 0.9907230138778687,
      "learning_rate": 1.3891797556719025e-05,
      "loss": 0.9464,
      "step": 3500
    },
    {
      "epoch": 0.9293193717277487,
      "grad_norm": 1.592445969581604,
      "learning_rate": 1.3804537521815009e-05,
      "loss": 0.9079,
      "step": 3550
    },
    {
      "epoch": 0.9424083769633508,
      "grad_norm": 3.7179832458496094,
      "learning_rate": 1.3717277486910996e-05,
      "loss": 0.9154,
      "step": 3600
    },
    {
      "epoch": 0.9554973821989529,
      "grad_norm": 2.043839693069458,
      "learning_rate": 1.3630017452006982e-05,
      "loss": 0.938,
      "step": 3650
    },
    {
      "epoch": 0.9685863874345549,
      "grad_norm": 3.0130717754364014,
      "learning_rate": 1.3542757417102968e-05,
      "loss": 0.9287,
      "step": 3700
    },
    {
      "epoch": 0.981675392670157,
      "grad_norm": 2.521247386932373,
      "learning_rate": 1.3455497382198954e-05,
      "loss": 0.9146,
      "step": 3750
    },
    {
      "epoch": 0.9947643979057592,
      "grad_norm": 2.3346762657165527,
      "learning_rate": 1.336823734729494e-05,
      "loss": 0.9318,
      "step": 3800
    },
    {
      "epoch": 1.0,
      "eval_runtime": 3.4472,
      "eval_samples_per_second": 240.193,
      "eval_steps_per_second": 15.085,
      "step": 3820
    }
  ],
  "logging_steps": 50,
  "max_steps": 11460,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4034216239349760.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
