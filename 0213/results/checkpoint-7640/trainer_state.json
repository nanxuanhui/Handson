{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 7640,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.013089005235602094,
      "grad_norm": 0.12118277698755264,
      "learning_rate": 1.9912739965095987e-05,
      "loss": 1.115,
      "step": 50
    },
    {
      "epoch": 0.02617801047120419,
      "grad_norm": 0.17336107790470123,
      "learning_rate": 1.9825479930191973e-05,
      "loss": 1.1158,
      "step": 100
    },
    {
      "epoch": 0.03926701570680628,
      "grad_norm": 0.3817252516746521,
      "learning_rate": 1.973821989528796e-05,
      "loss": 1.1155,
      "step": 150
    },
    {
      "epoch": 0.05235602094240838,
      "grad_norm": 0.20205768942832947,
      "learning_rate": 1.9650959860383945e-05,
      "loss": 1.116,
      "step": 200
    },
    {
      "epoch": 0.06544502617801047,
      "grad_norm": 0.19136646389961243,
      "learning_rate": 1.956369982547993e-05,
      "loss": 1.0893,
      "step": 250
    },
    {
      "epoch": 0.07853403141361257,
      "grad_norm": 0.3084053099155426,
      "learning_rate": 1.947643979057592e-05,
      "loss": 1.0854,
      "step": 300
    },
    {
      "epoch": 0.09162303664921466,
      "grad_norm": 0.32901453971862793,
      "learning_rate": 1.9389179755671902e-05,
      "loss": 1.0923,
      "step": 350
    },
    {
      "epoch": 0.10471204188481675,
      "grad_norm": 0.32096418738365173,
      "learning_rate": 1.930191972076789e-05,
      "loss": 1.0846,
      "step": 400
    },
    {
      "epoch": 0.11780104712041885,
      "grad_norm": 0.3386801481246948,
      "learning_rate": 1.9214659685863877e-05,
      "loss": 1.084,
      "step": 450
    },
    {
      "epoch": 0.13089005235602094,
      "grad_norm": 0.46849507093429565,
      "learning_rate": 1.9127399650959863e-05,
      "loss": 1.0753,
      "step": 500
    },
    {
      "epoch": 0.14397905759162305,
      "grad_norm": 0.373625785112381,
      "learning_rate": 1.904013961605585e-05,
      "loss": 1.0676,
      "step": 550
    },
    {
      "epoch": 0.15706806282722513,
      "grad_norm": 0.6743139028549194,
      "learning_rate": 1.895287958115183e-05,
      "loss": 1.0772,
      "step": 600
    },
    {
      "epoch": 0.17015706806282724,
      "grad_norm": 0.506660521030426,
      "learning_rate": 1.886561954624782e-05,
      "loss": 1.0668,
      "step": 650
    },
    {
      "epoch": 0.18324607329842932,
      "grad_norm": 0.4669664800167084,
      "learning_rate": 1.8778359511343806e-05,
      "loss": 1.0579,
      "step": 700
    },
    {
      "epoch": 0.19633507853403143,
      "grad_norm": 1.4325381517410278,
      "learning_rate": 1.8691099476439792e-05,
      "loss": 1.0444,
      "step": 750
    },
    {
      "epoch": 0.2094240837696335,
      "grad_norm": 0.841909646987915,
      "learning_rate": 1.8603839441535778e-05,
      "loss": 1.0404,
      "step": 800
    },
    {
      "epoch": 0.22251308900523561,
      "grad_norm": 0.9710665941238403,
      "learning_rate": 1.8516579406631764e-05,
      "loss": 1.0468,
      "step": 850
    },
    {
      "epoch": 0.2356020942408377,
      "grad_norm": 0.4884214401245117,
      "learning_rate": 1.842931937172775e-05,
      "loss": 1.0239,
      "step": 900
    },
    {
      "epoch": 0.2486910994764398,
      "grad_norm": 1.8202688694000244,
      "learning_rate": 1.8342059336823735e-05,
      "loss": 1.0434,
      "step": 950
    },
    {
      "epoch": 0.2617801047120419,
      "grad_norm": 0.9531408548355103,
      "learning_rate": 1.825479930191972e-05,
      "loss": 1.0427,
      "step": 1000
    },
    {
      "epoch": 0.27486910994764396,
      "grad_norm": 0.487871915102005,
      "learning_rate": 1.8167539267015707e-05,
      "loss": 1.0428,
      "step": 1050
    },
    {
      "epoch": 0.2879581151832461,
      "grad_norm": 1.1555445194244385,
      "learning_rate": 1.8080279232111696e-05,
      "loss": 1.0366,
      "step": 1100
    },
    {
      "epoch": 0.3010471204188482,
      "grad_norm": 0.6162355542182922,
      "learning_rate": 1.799301919720768e-05,
      "loss": 1.0178,
      "step": 1150
    },
    {
      "epoch": 0.31413612565445026,
      "grad_norm": 0.6140527129173279,
      "learning_rate": 1.7905759162303668e-05,
      "loss": 1.0302,
      "step": 1200
    },
    {
      "epoch": 0.32722513089005234,
      "grad_norm": 0.6246379017829895,
      "learning_rate": 1.7818499127399654e-05,
      "loss": 1.0312,
      "step": 1250
    },
    {
      "epoch": 0.3403141361256545,
      "grad_norm": 0.7229703664779663,
      "learning_rate": 1.773123909249564e-05,
      "loss": 1.0313,
      "step": 1300
    },
    {
      "epoch": 0.35340314136125656,
      "grad_norm": 1.373700499534607,
      "learning_rate": 1.7643979057591625e-05,
      "loss": 1.0133,
      "step": 1350
    },
    {
      "epoch": 0.36649214659685864,
      "grad_norm": 0.9335792660713196,
      "learning_rate": 1.755671902268761e-05,
      "loss": 1.033,
      "step": 1400
    },
    {
      "epoch": 0.3795811518324607,
      "grad_norm": 2.1842923164367676,
      "learning_rate": 1.7469458987783597e-05,
      "loss": 1.0192,
      "step": 1450
    },
    {
      "epoch": 0.39267015706806285,
      "grad_norm": 0.8742027282714844,
      "learning_rate": 1.7382198952879583e-05,
      "loss": 1.0349,
      "step": 1500
    },
    {
      "epoch": 0.40575916230366493,
      "grad_norm": 0.6279504895210266,
      "learning_rate": 1.729493891797557e-05,
      "loss": 1.0252,
      "step": 1550
    },
    {
      "epoch": 0.418848167539267,
      "grad_norm": 0.8896008729934692,
      "learning_rate": 1.7207678883071554e-05,
      "loss": 1.0386,
      "step": 1600
    },
    {
      "epoch": 0.4319371727748691,
      "grad_norm": 0.57406085729599,
      "learning_rate": 1.712041884816754e-05,
      "loss": 1.028,
      "step": 1650
    },
    {
      "epoch": 0.44502617801047123,
      "grad_norm": 0.6361834406852722,
      "learning_rate": 1.7033158813263526e-05,
      "loss": 1.0141,
      "step": 1700
    },
    {
      "epoch": 0.4581151832460733,
      "grad_norm": 0.49638131260871887,
      "learning_rate": 1.694589877835951e-05,
      "loss": 1.0103,
      "step": 1750
    },
    {
      "epoch": 0.4712041884816754,
      "grad_norm": 2.087602376937866,
      "learning_rate": 1.6858638743455497e-05,
      "loss": 1.0076,
      "step": 1800
    },
    {
      "epoch": 0.48429319371727747,
      "grad_norm": 0.8858644366264343,
      "learning_rate": 1.6771378708551483e-05,
      "loss": 1.0138,
      "step": 1850
    },
    {
      "epoch": 0.4973821989528796,
      "grad_norm": 0.9705279469490051,
      "learning_rate": 1.6684118673647472e-05,
      "loss": 1.0266,
      "step": 1900
    },
    {
      "epoch": 0.5104712041884817,
      "grad_norm": 0.9348119497299194,
      "learning_rate": 1.6596858638743455e-05,
      "loss": 1.0013,
      "step": 1950
    },
    {
      "epoch": 0.5235602094240838,
      "grad_norm": 0.8809092044830322,
      "learning_rate": 1.6509598603839444e-05,
      "loss": 1.0176,
      "step": 2000
    },
    {
      "epoch": 0.5366492146596858,
      "grad_norm": 0.9426864981651306,
      "learning_rate": 1.642233856893543e-05,
      "loss": 0.9743,
      "step": 2050
    },
    {
      "epoch": 0.5497382198952879,
      "grad_norm": 1.5908390283584595,
      "learning_rate": 1.6335078534031416e-05,
      "loss": 0.9934,
      "step": 2100
    },
    {
      "epoch": 0.56282722513089,
      "grad_norm": 0.6813254356384277,
      "learning_rate": 1.62478184991274e-05,
      "loss": 1.0186,
      "step": 2150
    },
    {
      "epoch": 0.5759162303664922,
      "grad_norm": 2.6370980739593506,
      "learning_rate": 1.6160558464223387e-05,
      "loss": 0.9976,
      "step": 2200
    },
    {
      "epoch": 0.5890052356020943,
      "grad_norm": 0.702314555644989,
      "learning_rate": 1.6073298429319373e-05,
      "loss": 1.0086,
      "step": 2250
    },
    {
      "epoch": 0.6020942408376964,
      "grad_norm": 1.1896488666534424,
      "learning_rate": 1.598603839441536e-05,
      "loss": 1.0061,
      "step": 2300
    },
    {
      "epoch": 0.6151832460732984,
      "grad_norm": 0.961165189743042,
      "learning_rate": 1.5898778359511345e-05,
      "loss": 1.0104,
      "step": 2350
    },
    {
      "epoch": 0.6282722513089005,
      "grad_norm": 1.0108668804168701,
      "learning_rate": 1.581151832460733e-05,
      "loss": 1.0076,
      "step": 2400
    },
    {
      "epoch": 0.6413612565445026,
      "grad_norm": 0.8675951361656189,
      "learning_rate": 1.572425828970332e-05,
      "loss": 0.9944,
      "step": 2450
    },
    {
      "epoch": 0.6544502617801047,
      "grad_norm": 1.4629746675491333,
      "learning_rate": 1.5636998254799302e-05,
      "loss": 0.9923,
      "step": 2500
    },
    {
      "epoch": 0.6675392670157068,
      "grad_norm": 0.8532177209854126,
      "learning_rate": 1.554973821989529e-05,
      "loss": 0.9868,
      "step": 2550
    },
    {
      "epoch": 0.680628272251309,
      "grad_norm": 1.1253283023834229,
      "learning_rate": 1.5462478184991274e-05,
      "loss": 0.9736,
      "step": 2600
    },
    {
      "epoch": 0.693717277486911,
      "grad_norm": 1.020376205444336,
      "learning_rate": 1.537521815008726e-05,
      "loss": 0.9994,
      "step": 2650
    },
    {
      "epoch": 0.7068062827225131,
      "grad_norm": 1.0807418823242188,
      "learning_rate": 1.528795811518325e-05,
      "loss": 0.9913,
      "step": 2700
    },
    {
      "epoch": 0.7198952879581152,
      "grad_norm": 1.0435155630111694,
      "learning_rate": 1.5200698080279233e-05,
      "loss": 0.9905,
      "step": 2750
    },
    {
      "epoch": 0.7329842931937173,
      "grad_norm": 1.7948681116104126,
      "learning_rate": 1.511343804537522e-05,
      "loss": 0.9823,
      "step": 2800
    },
    {
      "epoch": 0.7460732984293194,
      "grad_norm": 1.1531685590744019,
      "learning_rate": 1.5026178010471206e-05,
      "loss": 1.0055,
      "step": 2850
    },
    {
      "epoch": 0.7591623036649214,
      "grad_norm": 1.145842432975769,
      "learning_rate": 1.493891797556719e-05,
      "loss": 0.9838,
      "step": 2900
    },
    {
      "epoch": 0.7722513089005235,
      "grad_norm": 1.5351519584655762,
      "learning_rate": 1.4851657940663178e-05,
      "loss": 0.9758,
      "step": 2950
    },
    {
      "epoch": 0.7853403141361257,
      "grad_norm": 1.4190806150436401,
      "learning_rate": 1.4764397905759162e-05,
      "loss": 0.975,
      "step": 3000
    },
    {
      "epoch": 0.7984293193717278,
      "grad_norm": 1.2193337678909302,
      "learning_rate": 1.467713787085515e-05,
      "loss": 0.9827,
      "step": 3050
    },
    {
      "epoch": 0.8115183246073299,
      "grad_norm": 1.4238009452819824,
      "learning_rate": 1.4589877835951137e-05,
      "loss": 0.9653,
      "step": 3100
    },
    {
      "epoch": 0.824607329842932,
      "grad_norm": 1.4011480808258057,
      "learning_rate": 1.450261780104712e-05,
      "loss": 0.9684,
      "step": 3150
    },
    {
      "epoch": 0.837696335078534,
      "grad_norm": 1.377386450767517,
      "learning_rate": 1.4415357766143108e-05,
      "loss": 0.9633,
      "step": 3200
    },
    {
      "epoch": 0.8507853403141361,
      "grad_norm": 1.2685871124267578,
      "learning_rate": 1.4328097731239094e-05,
      "loss": 0.9677,
      "step": 3250
    },
    {
      "epoch": 0.8638743455497382,
      "grad_norm": 1.1994205713272095,
      "learning_rate": 1.424083769633508e-05,
      "loss": 0.936,
      "step": 3300
    },
    {
      "epoch": 0.8769633507853403,
      "grad_norm": 1.790286660194397,
      "learning_rate": 1.4153577661431066e-05,
      "loss": 0.9305,
      "step": 3350
    },
    {
      "epoch": 0.8900523560209425,
      "grad_norm": 1.3403974771499634,
      "learning_rate": 1.4066317626527052e-05,
      "loss": 0.9515,
      "step": 3400
    },
    {
      "epoch": 0.9031413612565445,
      "grad_norm": 2.375913143157959,
      "learning_rate": 1.3979057591623037e-05,
      "loss": 0.9509,
      "step": 3450
    },
    {
      "epoch": 0.9162303664921466,
      "grad_norm": 0.9907230138778687,
      "learning_rate": 1.3891797556719025e-05,
      "loss": 0.9464,
      "step": 3500
    },
    {
      "epoch": 0.9293193717277487,
      "grad_norm": 1.592445969581604,
      "learning_rate": 1.3804537521815009e-05,
      "loss": 0.9079,
      "step": 3550
    },
    {
      "epoch": 0.9424083769633508,
      "grad_norm": 3.7179832458496094,
      "learning_rate": 1.3717277486910996e-05,
      "loss": 0.9154,
      "step": 3600
    },
    {
      "epoch": 0.9554973821989529,
      "grad_norm": 2.043839693069458,
      "learning_rate": 1.3630017452006982e-05,
      "loss": 0.938,
      "step": 3650
    },
    {
      "epoch": 0.9685863874345549,
      "grad_norm": 3.0130717754364014,
      "learning_rate": 1.3542757417102968e-05,
      "loss": 0.9287,
      "step": 3700
    },
    {
      "epoch": 0.981675392670157,
      "grad_norm": 2.521247386932373,
      "learning_rate": 1.3455497382198954e-05,
      "loss": 0.9146,
      "step": 3750
    },
    {
      "epoch": 0.9947643979057592,
      "grad_norm": 2.3346762657165527,
      "learning_rate": 1.336823734729494e-05,
      "loss": 0.9318,
      "step": 3800
    },
    {
      "epoch": 1.0,
      "eval_runtime": 3.4472,
      "eval_samples_per_second": 240.193,
      "eval_steps_per_second": 15.085,
      "step": 3820
    },
    {
      "epoch": 1.0078534031413613,
      "grad_norm": 1.278563141822815,
      "learning_rate": 1.3280977312390925e-05,
      "loss": 0.9088,
      "step": 3850
    },
    {
      "epoch": 1.0209424083769634,
      "grad_norm": 2.8277533054351807,
      "learning_rate": 1.3193717277486913e-05,
      "loss": 0.9269,
      "step": 3900
    },
    {
      "epoch": 1.0340314136125655,
      "grad_norm": 1.1904146671295166,
      "learning_rate": 1.3106457242582897e-05,
      "loss": 0.9147,
      "step": 3950
    },
    {
      "epoch": 1.0471204188481675,
      "grad_norm": 2.471531391143799,
      "learning_rate": 1.3019197207678885e-05,
      "loss": 0.9189,
      "step": 4000
    },
    {
      "epoch": 1.0602094240837696,
      "grad_norm": 1.571066975593567,
      "learning_rate": 1.293193717277487e-05,
      "loss": 0.8988,
      "step": 4050
    },
    {
      "epoch": 1.0732984293193717,
      "grad_norm": 1.5904109477996826,
      "learning_rate": 1.2844677137870856e-05,
      "loss": 0.8969,
      "step": 4100
    },
    {
      "epoch": 1.0863874345549738,
      "grad_norm": 5.1125359535217285,
      "learning_rate": 1.2757417102966842e-05,
      "loss": 0.9009,
      "step": 4150
    },
    {
      "epoch": 1.0994764397905759,
      "grad_norm": 1.8844205141067505,
      "learning_rate": 1.2670157068062828e-05,
      "loss": 0.8821,
      "step": 4200
    },
    {
      "epoch": 1.112565445026178,
      "grad_norm": 3.275470733642578,
      "learning_rate": 1.2582897033158814e-05,
      "loss": 0.8831,
      "step": 4250
    },
    {
      "epoch": 1.12565445026178,
      "grad_norm": 1.445709228515625,
      "learning_rate": 1.2495636998254801e-05,
      "loss": 0.9004,
      "step": 4300
    },
    {
      "epoch": 1.1387434554973823,
      "grad_norm": 1.8207932710647583,
      "learning_rate": 1.2408376963350785e-05,
      "loss": 0.8989,
      "step": 4350
    },
    {
      "epoch": 1.1518324607329844,
      "grad_norm": 2.161489725112915,
      "learning_rate": 1.2321116928446773e-05,
      "loss": 0.8937,
      "step": 4400
    },
    {
      "epoch": 1.1649214659685865,
      "grad_norm": 1.6832765340805054,
      "learning_rate": 1.2233856893542758e-05,
      "loss": 0.8797,
      "step": 4450
    },
    {
      "epoch": 1.1780104712041886,
      "grad_norm": 1.9004144668579102,
      "learning_rate": 1.2146596858638744e-05,
      "loss": 0.8872,
      "step": 4500
    },
    {
      "epoch": 1.1910994764397906,
      "grad_norm": 1.269290804862976,
      "learning_rate": 1.205933682373473e-05,
      "loss": 0.86,
      "step": 4550
    },
    {
      "epoch": 1.2041884816753927,
      "grad_norm": 2.7547767162323,
      "learning_rate": 1.1972076788830716e-05,
      "loss": 0.8653,
      "step": 4600
    },
    {
      "epoch": 1.2172774869109948,
      "grad_norm": 1.952684998512268,
      "learning_rate": 1.1884816753926702e-05,
      "loss": 0.8747,
      "step": 4650
    },
    {
      "epoch": 1.2303664921465969,
      "grad_norm": 1.991668701171875,
      "learning_rate": 1.179755671902269e-05,
      "loss": 0.8562,
      "step": 4700
    },
    {
      "epoch": 1.243455497382199,
      "grad_norm": 1.5376319885253906,
      "learning_rate": 1.1710296684118673e-05,
      "loss": 0.8656,
      "step": 4750
    },
    {
      "epoch": 1.256544502617801,
      "grad_norm": 2.932345390319824,
      "learning_rate": 1.162303664921466e-05,
      "loss": 0.8534,
      "step": 4800
    },
    {
      "epoch": 1.2696335078534031,
      "grad_norm": 2.0792076587677,
      "learning_rate": 1.1535776614310648e-05,
      "loss": 0.8879,
      "step": 4850
    },
    {
      "epoch": 1.2827225130890052,
      "grad_norm": 1.5170563459396362,
      "learning_rate": 1.1448516579406632e-05,
      "loss": 0.8644,
      "step": 4900
    },
    {
      "epoch": 1.2958115183246073,
      "grad_norm": 1.7789674997329712,
      "learning_rate": 1.1361256544502618e-05,
      "loss": 0.8812,
      "step": 4950
    },
    {
      "epoch": 1.3089005235602094,
      "grad_norm": 1.3850574493408203,
      "learning_rate": 1.1273996509598604e-05,
      "loss": 0.8447,
      "step": 5000
    },
    {
      "epoch": 1.3219895287958114,
      "grad_norm": 2.3683114051818848,
      "learning_rate": 1.118673647469459e-05,
      "loss": 0.8684,
      "step": 5050
    },
    {
      "epoch": 1.3350785340314135,
      "grad_norm": 2.9799916744232178,
      "learning_rate": 1.1099476439790577e-05,
      "loss": 0.84,
      "step": 5100
    },
    {
      "epoch": 1.3481675392670156,
      "grad_norm": 2.7161073684692383,
      "learning_rate": 1.1012216404886561e-05,
      "loss": 0.8847,
      "step": 5150
    },
    {
      "epoch": 1.3612565445026177,
      "grad_norm": 1.4847365617752075,
      "learning_rate": 1.0924956369982549e-05,
      "loss": 0.8571,
      "step": 5200
    },
    {
      "epoch": 1.3743455497382198,
      "grad_norm": 2.839188814163208,
      "learning_rate": 1.0837696335078536e-05,
      "loss": 0.8784,
      "step": 5250
    },
    {
      "epoch": 1.387434554973822,
      "grad_norm": 1.9900130033493042,
      "learning_rate": 1.075043630017452e-05,
      "loss": 0.8856,
      "step": 5300
    },
    {
      "epoch": 1.4005235602094241,
      "grad_norm": 2.473986864089966,
      "learning_rate": 1.0663176265270508e-05,
      "loss": 0.8678,
      "step": 5350
    },
    {
      "epoch": 1.4136125654450262,
      "grad_norm": 1.6810969114303589,
      "learning_rate": 1.0575916230366492e-05,
      "loss": 0.8178,
      "step": 5400
    },
    {
      "epoch": 1.4267015706806283,
      "grad_norm": 2.233835220336914,
      "learning_rate": 1.048865619546248e-05,
      "loss": 0.851,
      "step": 5450
    },
    {
      "epoch": 1.4397905759162304,
      "grad_norm": 2.5557408332824707,
      "learning_rate": 1.0401396160558465e-05,
      "loss": 0.8732,
      "step": 5500
    },
    {
      "epoch": 1.4528795811518325,
      "grad_norm": 5.833676815032959,
      "learning_rate": 1.031413612565445e-05,
      "loss": 0.8409,
      "step": 5550
    },
    {
      "epoch": 1.4659685863874345,
      "grad_norm": 2.601451873779297,
      "learning_rate": 1.0226876090750437e-05,
      "loss": 0.8331,
      "step": 5600
    },
    {
      "epoch": 1.4790575916230366,
      "grad_norm": 3.5005624294281006,
      "learning_rate": 1.0139616055846425e-05,
      "loss": 0.8641,
      "step": 5650
    },
    {
      "epoch": 1.4921465968586387,
      "grad_norm": 2.9986345767974854,
      "learning_rate": 1.0052356020942409e-05,
      "loss": 0.8482,
      "step": 5700
    },
    {
      "epoch": 1.5052356020942408,
      "grad_norm": 2.3536689281463623,
      "learning_rate": 9.965095986038396e-06,
      "loss": 0.8547,
      "step": 5750
    },
    {
      "epoch": 1.518324607329843,
      "grad_norm": 2.80464506149292,
      "learning_rate": 9.877835951134382e-06,
      "loss": 0.8588,
      "step": 5800
    },
    {
      "epoch": 1.5314136125654452,
      "grad_norm": 1.7286456823349,
      "learning_rate": 9.790575916230368e-06,
      "loss": 0.8368,
      "step": 5850
    },
    {
      "epoch": 1.5445026178010473,
      "grad_norm": 1.5580425262451172,
      "learning_rate": 9.703315881326354e-06,
      "loss": 0.8196,
      "step": 5900
    },
    {
      "epoch": 1.5575916230366493,
      "grad_norm": 1.7789636850357056,
      "learning_rate": 9.61605584642234e-06,
      "loss": 0.8349,
      "step": 5950
    },
    {
      "epoch": 1.5706806282722514,
      "grad_norm": 1.811590313911438,
      "learning_rate": 9.528795811518325e-06,
      "loss": 0.829,
      "step": 6000
    },
    {
      "epoch": 1.5837696335078535,
      "grad_norm": 1.9018819332122803,
      "learning_rate": 9.441535776614311e-06,
      "loss": 0.8357,
      "step": 6050
    },
    {
      "epoch": 1.5968586387434556,
      "grad_norm": 2.4238710403442383,
      "learning_rate": 9.354275741710297e-06,
      "loss": 0.8117,
      "step": 6100
    },
    {
      "epoch": 1.6099476439790577,
      "grad_norm": 2.7017602920532227,
      "learning_rate": 9.267015706806284e-06,
      "loss": 0.818,
      "step": 6150
    },
    {
      "epoch": 1.6230366492146597,
      "grad_norm": 3.9329402446746826,
      "learning_rate": 9.17975567190227e-06,
      "loss": 0.8328,
      "step": 6200
    },
    {
      "epoch": 1.6361256544502618,
      "grad_norm": 2.346749782562256,
      "learning_rate": 9.092495636998256e-06,
      "loss": 0.8399,
      "step": 6250
    },
    {
      "epoch": 1.649214659685864,
      "grad_norm": 1.5601551532745361,
      "learning_rate": 9.005235602094242e-06,
      "loss": 0.8556,
      "step": 6300
    },
    {
      "epoch": 1.662303664921466,
      "grad_norm": 1.8609222173690796,
      "learning_rate": 8.917975567190227e-06,
      "loss": 0.8348,
      "step": 6350
    },
    {
      "epoch": 1.675392670157068,
      "grad_norm": 3.75785756111145,
      "learning_rate": 8.830715532286213e-06,
      "loss": 0.8509,
      "step": 6400
    },
    {
      "epoch": 1.6884816753926701,
      "grad_norm": 2.0949692726135254,
      "learning_rate": 8.743455497382199e-06,
      "loss": 0.7867,
      "step": 6450
    },
    {
      "epoch": 1.7015706806282722,
      "grad_norm": 4.460891246795654,
      "learning_rate": 8.656195462478185e-06,
      "loss": 0.8419,
      "step": 6500
    },
    {
      "epoch": 1.7146596858638743,
      "grad_norm": 2.6954312324523926,
      "learning_rate": 8.568935427574172e-06,
      "loss": 0.8226,
      "step": 6550
    },
    {
      "epoch": 1.7277486910994764,
      "grad_norm": 1.2572908401489258,
      "learning_rate": 8.481675392670158e-06,
      "loss": 0.8329,
      "step": 6600
    },
    {
      "epoch": 1.7408376963350785,
      "grad_norm": 3.1700851917266846,
      "learning_rate": 8.394415357766144e-06,
      "loss": 0.8211,
      "step": 6650
    },
    {
      "epoch": 1.7539267015706805,
      "grad_norm": 1.8860417604446411,
      "learning_rate": 8.30715532286213e-06,
      "loss": 0.8611,
      "step": 6700
    },
    {
      "epoch": 1.7670157068062826,
      "grad_norm": 3.394249200820923,
      "learning_rate": 8.219895287958116e-06,
      "loss": 0.8092,
      "step": 6750
    },
    {
      "epoch": 1.7801047120418847,
      "grad_norm": 2.0876073837280273,
      "learning_rate": 8.132635253054101e-06,
      "loss": 0.8361,
      "step": 6800
    },
    {
      "epoch": 1.7931937172774868,
      "grad_norm": 3.4384775161743164,
      "learning_rate": 8.045375218150087e-06,
      "loss": 0.8168,
      "step": 6850
    },
    {
      "epoch": 1.8062827225130889,
      "grad_norm": 3.864570140838623,
      "learning_rate": 7.958115183246073e-06,
      "loss": 0.8263,
      "step": 6900
    },
    {
      "epoch": 1.819371727748691,
      "grad_norm": 3.4430465698242188,
      "learning_rate": 7.87085514834206e-06,
      "loss": 0.8251,
      "step": 6950
    },
    {
      "epoch": 1.8324607329842932,
      "grad_norm": 2.7167351245880127,
      "learning_rate": 7.783595113438046e-06,
      "loss": 0.841,
      "step": 7000
    },
    {
      "epoch": 1.8455497382198953,
      "grad_norm": 2.401614189147949,
      "learning_rate": 7.696335078534032e-06,
      "loss": 0.8025,
      "step": 7050
    },
    {
      "epoch": 1.8586387434554974,
      "grad_norm": 2.185201406478882,
      "learning_rate": 7.609075043630018e-06,
      "loss": 0.817,
      "step": 7100
    },
    {
      "epoch": 1.8717277486910995,
      "grad_norm": 2.4319300651550293,
      "learning_rate": 7.521815008726005e-06,
      "loss": 0.7985,
      "step": 7150
    },
    {
      "epoch": 1.8848167539267016,
      "grad_norm": 2.741758108139038,
      "learning_rate": 7.43455497382199e-06,
      "loss": 0.8359,
      "step": 7200
    },
    {
      "epoch": 1.8979057591623036,
      "grad_norm": 2.0391652584075928,
      "learning_rate": 7.347294938917976e-06,
      "loss": 0.8138,
      "step": 7250
    },
    {
      "epoch": 1.9109947643979057,
      "grad_norm": 2.750030755996704,
      "learning_rate": 7.260034904013962e-06,
      "loss": 0.8224,
      "step": 7300
    },
    {
      "epoch": 1.9240837696335078,
      "grad_norm": 2.1241908073425293,
      "learning_rate": 7.172774869109949e-06,
      "loss": 0.8294,
      "step": 7350
    },
    {
      "epoch": 1.93717277486911,
      "grad_norm": 2.8487730026245117,
      "learning_rate": 7.0855148342059345e-06,
      "loss": 0.8399,
      "step": 7400
    },
    {
      "epoch": 1.9502617801047122,
      "grad_norm": 4.371936321258545,
      "learning_rate": 6.99825479930192e-06,
      "loss": 0.8313,
      "step": 7450
    },
    {
      "epoch": 1.9633507853403143,
      "grad_norm": 1.942654013633728,
      "learning_rate": 6.910994764397906e-06,
      "loss": 0.8241,
      "step": 7500
    },
    {
      "epoch": 1.9764397905759163,
      "grad_norm": 2.255502462387085,
      "learning_rate": 6.823734729493893e-06,
      "loss": 0.8423,
      "step": 7550
    },
    {
      "epoch": 1.9895287958115184,
      "grad_norm": 2.0910708904266357,
      "learning_rate": 6.7364746945898785e-06,
      "loss": 0.7993,
      "step": 7600
    },
    {
      "epoch": 2.0,
      "eval_runtime": 3.01,
      "eval_samples_per_second": 275.084,
      "eval_steps_per_second": 17.276,
      "step": 7640
    }
  ],
  "logging_steps": 50,
  "max_steps": 11460,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 8068432478699520.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
