{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 3438,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.014543339150668994,
      "grad_norm": 0.16788017749786377,
      "learning_rate": 1.9903044405662208e-05,
      "loss": 1.0997,
      "step": 50
    },
    {
      "epoch": 0.029086678301337987,
      "grad_norm": 0.18294328451156616,
      "learning_rate": 1.9806088811324414e-05,
      "loss": 1.105,
      "step": 100
    },
    {
      "epoch": 0.04363001745200698,
      "grad_norm": 0.21495305001735687,
      "learning_rate": 1.9709133216986623e-05,
      "loss": 1.0974,
      "step": 150
    },
    {
      "epoch": 0.058173356602675974,
      "grad_norm": 0.3078765869140625,
      "learning_rate": 1.961217762264883e-05,
      "loss": 1.0924,
      "step": 200
    },
    {
      "epoch": 0.07271669575334497,
      "grad_norm": 0.19562458992004395,
      "learning_rate": 1.9515222028311035e-05,
      "loss": 1.092,
      "step": 250
    },
    {
      "epoch": 0.08726003490401396,
      "grad_norm": 0.20552143454551697,
      "learning_rate": 1.941826643397324e-05,
      "loss": 1.0885,
      "step": 300
    },
    {
      "epoch": 0.10180337405468295,
      "grad_norm": 0.2593512535095215,
      "learning_rate": 1.9321310839635448e-05,
      "loss": 1.0952,
      "step": 350
    },
    {
      "epoch": 0.11634671320535195,
      "grad_norm": 0.21192769706249237,
      "learning_rate": 1.9224355245297654e-05,
      "loss": 1.0824,
      "step": 400
    },
    {
      "epoch": 0.13089005235602094,
      "grad_norm": 0.24882808327674866,
      "learning_rate": 1.9127399650959863e-05,
      "loss": 1.0802,
      "step": 450
    },
    {
      "epoch": 0.14543339150668994,
      "grad_norm": 0.2248670607805252,
      "learning_rate": 1.903044405662207e-05,
      "loss": 1.0642,
      "step": 500
    },
    {
      "epoch": 0.15997673065735893,
      "grad_norm": 0.38020244240760803,
      "learning_rate": 1.8933488462284275e-05,
      "loss": 1.0831,
      "step": 550
    },
    {
      "epoch": 0.17452006980802792,
      "grad_norm": 0.2428826242685318,
      "learning_rate": 1.883653286794648e-05,
      "loss": 1.0701,
      "step": 600
    },
    {
      "epoch": 0.18906340895869692,
      "grad_norm": 0.30840033292770386,
      "learning_rate": 1.8739577273608687e-05,
      "loss": 1.0646,
      "step": 650
    },
    {
      "epoch": 0.2036067481093659,
      "grad_norm": 0.520590603351593,
      "learning_rate": 1.8642621679270897e-05,
      "loss": 1.0528,
      "step": 700
    },
    {
      "epoch": 0.2181500872600349,
      "grad_norm": 0.3894437253475189,
      "learning_rate": 1.8545666084933103e-05,
      "loss": 1.0565,
      "step": 750
    },
    {
      "epoch": 0.2326934264107039,
      "grad_norm": 0.3527175188064575,
      "learning_rate": 1.844871049059531e-05,
      "loss": 1.0481,
      "step": 800
    },
    {
      "epoch": 0.2472367655613729,
      "grad_norm": 0.460554301738739,
      "learning_rate": 1.8351754896257515e-05,
      "loss": 1.0399,
      "step": 850
    },
    {
      "epoch": 0.2617801047120419,
      "grad_norm": 0.5095324516296387,
      "learning_rate": 1.825479930191972e-05,
      "loss": 1.0481,
      "step": 900
    },
    {
      "epoch": 0.2763234438627109,
      "grad_norm": 0.7971974611282349,
      "learning_rate": 1.8157843707581927e-05,
      "loss": 1.0355,
      "step": 950
    },
    {
      "epoch": 0.29086678301337987,
      "grad_norm": 0.9746623635292053,
      "learning_rate": 1.8060888113244137e-05,
      "loss": 1.0255,
      "step": 1000
    },
    {
      "epoch": 0.3054101221640489,
      "grad_norm": 0.49875685572624207,
      "learning_rate": 1.7963932518906343e-05,
      "loss": 1.0265,
      "step": 1050
    },
    {
      "epoch": 0.31995346131471786,
      "grad_norm": 0.7884096503257751,
      "learning_rate": 1.786697692456855e-05,
      "loss": 1.0138,
      "step": 1100
    },
    {
      "epoch": 0.3344968004653869,
      "grad_norm": 0.49243679642677307,
      "learning_rate": 1.7770021330230755e-05,
      "loss": 1.0183,
      "step": 1150
    },
    {
      "epoch": 0.34904013961605584,
      "grad_norm": 0.5400419235229492,
      "learning_rate": 1.767306573589296e-05,
      "loss": 1.0106,
      "step": 1200
    },
    {
      "epoch": 0.36358347876672487,
      "grad_norm": 1.2440197467803955,
      "learning_rate": 1.757611014155517e-05,
      "loss": 1.0144,
      "step": 1250
    },
    {
      "epoch": 0.37812681791739383,
      "grad_norm": 0.7493194341659546,
      "learning_rate": 1.7479154547217376e-05,
      "loss": 1.0225,
      "step": 1300
    },
    {
      "epoch": 0.39267015706806285,
      "grad_norm": 0.8269922733306885,
      "learning_rate": 1.7382198952879583e-05,
      "loss": 1.0124,
      "step": 1350
    },
    {
      "epoch": 0.4072134962187318,
      "grad_norm": 0.5032435655593872,
      "learning_rate": 1.728524335854179e-05,
      "loss": 0.9975,
      "step": 1400
    },
    {
      "epoch": 0.42175683536940084,
      "grad_norm": 1.4443092346191406,
      "learning_rate": 1.7188287764203998e-05,
      "loss": 1.0045,
      "step": 1450
    },
    {
      "epoch": 0.4363001745200698,
      "grad_norm": 1.4012094736099243,
      "learning_rate": 1.70913321698662e-05,
      "loss": 1.0147,
      "step": 1500
    },
    {
      "epoch": 0.4508435136707388,
      "grad_norm": 1.237355351448059,
      "learning_rate": 1.6994376575528407e-05,
      "loss": 1.0141,
      "step": 1550
    },
    {
      "epoch": 0.4653868528214078,
      "grad_norm": 0.7641737461090088,
      "learning_rate": 1.6897420981190616e-05,
      "loss": 1.0024,
      "step": 1600
    },
    {
      "epoch": 0.4799301919720768,
      "grad_norm": 0.9094364643096924,
      "learning_rate": 1.6800465386852822e-05,
      "loss": 0.9928,
      "step": 1650
    },
    {
      "epoch": 0.4944735311227458,
      "grad_norm": 0.9269793629646301,
      "learning_rate": 1.670350979251503e-05,
      "loss": 0.9915,
      "step": 1700
    },
    {
      "epoch": 0.5090168702734148,
      "grad_norm": 1.1587198972702026,
      "learning_rate": 1.6606554198177234e-05,
      "loss": 0.9983,
      "step": 1750
    },
    {
      "epoch": 0.5235602094240838,
      "grad_norm": 1.0883551836013794,
      "learning_rate": 1.6509598603839444e-05,
      "loss": 0.9847,
      "step": 1800
    },
    {
      "epoch": 0.5381035485747527,
      "grad_norm": 1.1649166345596313,
      "learning_rate": 1.641264300950165e-05,
      "loss": 0.9671,
      "step": 1850
    },
    {
      "epoch": 0.5526468877254218,
      "grad_norm": 0.5367815494537354,
      "learning_rate": 1.6315687415163856e-05,
      "loss": 0.9656,
      "step": 1900
    },
    {
      "epoch": 0.5671902268760908,
      "grad_norm": 1.01108980178833,
      "learning_rate": 1.6218731820826062e-05,
      "loss": 1.0047,
      "step": 1950
    },
    {
      "epoch": 0.5817335660267597,
      "grad_norm": 0.9761399030685425,
      "learning_rate": 1.612177622648827e-05,
      "loss": 0.9608,
      "step": 2000
    },
    {
      "epoch": 0.5962769051774287,
      "grad_norm": 1.5452585220336914,
      "learning_rate": 1.6024820632150478e-05,
      "loss": 0.987,
      "step": 2050
    },
    {
      "epoch": 0.6108202443280978,
      "grad_norm": 1.3247030973434448,
      "learning_rate": 1.592786503781268e-05,
      "loss": 0.9492,
      "step": 2100
    },
    {
      "epoch": 0.6253635834787667,
      "grad_norm": 1.5299296379089355,
      "learning_rate": 1.583090944347489e-05,
      "loss": 0.9556,
      "step": 2150
    },
    {
      "epoch": 0.6399069226294357,
      "grad_norm": 1.6764227151870728,
      "learning_rate": 1.5733953849137096e-05,
      "loss": 0.9675,
      "step": 2200
    },
    {
      "epoch": 0.6544502617801047,
      "grad_norm": 1.23341703414917,
      "learning_rate": 1.5636998254799302e-05,
      "loss": 0.9316,
      "step": 2250
    },
    {
      "epoch": 0.6689936009307738,
      "grad_norm": 1.5735788345336914,
      "learning_rate": 1.5540042660461508e-05,
      "loss": 0.9454,
      "step": 2300
    },
    {
      "epoch": 0.6835369400814427,
      "grad_norm": 1.0533101558685303,
      "learning_rate": 1.5443087066123718e-05,
      "loss": 0.9542,
      "step": 2350
    },
    {
      "epoch": 0.6980802792321117,
      "grad_norm": 2.1039116382598877,
      "learning_rate": 1.5346131471785924e-05,
      "loss": 0.9374,
      "step": 2400
    },
    {
      "epoch": 0.7126236183827807,
      "grad_norm": 1.108399510383606,
      "learning_rate": 1.524917587744813e-05,
      "loss": 0.9611,
      "step": 2450
    },
    {
      "epoch": 0.7271669575334497,
      "grad_norm": 1.1599948406219482,
      "learning_rate": 1.5152220283110337e-05,
      "loss": 0.9368,
      "step": 2500
    },
    {
      "epoch": 0.7417102966841187,
      "grad_norm": 1.4949065446853638,
      "learning_rate": 1.5055264688772543e-05,
      "loss": 0.9473,
      "step": 2550
    },
    {
      "epoch": 0.7562536358347877,
      "grad_norm": 1.7248305082321167,
      "learning_rate": 1.4958309094434751e-05,
      "loss": 0.9185,
      "step": 2600
    },
    {
      "epoch": 0.7707969749854566,
      "grad_norm": 1.9212870597839355,
      "learning_rate": 1.4861353500096957e-05,
      "loss": 0.9298,
      "step": 2650
    },
    {
      "epoch": 0.7853403141361257,
      "grad_norm": 1.8944404125213623,
      "learning_rate": 1.4764397905759162e-05,
      "loss": 0.9113,
      "step": 2700
    },
    {
      "epoch": 0.7998836532867947,
      "grad_norm": 2.154203176498413,
      "learning_rate": 1.466744231142137e-05,
      "loss": 0.9144,
      "step": 2750
    },
    {
      "epoch": 0.8144269924374636,
      "grad_norm": 1.4115835428237915,
      "learning_rate": 1.4570486717083576e-05,
      "loss": 0.9159,
      "step": 2800
    },
    {
      "epoch": 0.8289703315881326,
      "grad_norm": 1.5214699506759644,
      "learning_rate": 1.4473531122745783e-05,
      "loss": 0.9359,
      "step": 2850
    },
    {
      "epoch": 0.8435136707388017,
      "grad_norm": 2.000627279281616,
      "learning_rate": 1.437657552840799e-05,
      "loss": 0.9092,
      "step": 2900
    },
    {
      "epoch": 0.8580570098894706,
      "grad_norm": 1.064439058303833,
      "learning_rate": 1.4279619934070197e-05,
      "loss": 0.9212,
      "step": 2950
    },
    {
      "epoch": 0.8726003490401396,
      "grad_norm": 1.4689940214157104,
      "learning_rate": 1.4182664339732403e-05,
      "loss": 0.9021,
      "step": 3000
    },
    {
      "epoch": 0.8871436881908086,
      "grad_norm": 1.2985926866531372,
      "learning_rate": 1.4085708745394611e-05,
      "loss": 0.898,
      "step": 3050
    },
    {
      "epoch": 0.9016870273414777,
      "grad_norm": 2.2445781230926514,
      "learning_rate": 1.3988753151056817e-05,
      "loss": 0.9176,
      "step": 3100
    },
    {
      "epoch": 0.9162303664921466,
      "grad_norm": 1.2839672565460205,
      "learning_rate": 1.3891797556719025e-05,
      "loss": 0.931,
      "step": 3150
    },
    {
      "epoch": 0.9307737056428156,
      "grad_norm": 3.6549088954925537,
      "learning_rate": 1.3794841962381231e-05,
      "loss": 0.8722,
      "step": 3200
    },
    {
      "epoch": 0.9453170447934846,
      "grad_norm": 1.5878241062164307,
      "learning_rate": 1.3697886368043439e-05,
      "loss": 0.8892,
      "step": 3250
    },
    {
      "epoch": 0.9598603839441536,
      "grad_norm": 1.8238805532455444,
      "learning_rate": 1.3600930773705643e-05,
      "loss": 0.8708,
      "step": 3300
    },
    {
      "epoch": 0.9744037230948226,
      "grad_norm": 2.0244758129119873,
      "learning_rate": 1.3503975179367849e-05,
      "loss": 0.8767,
      "step": 3350
    },
    {
      "epoch": 0.9889470622454916,
      "grad_norm": 1.3520935773849487,
      "learning_rate": 1.3407019585030057e-05,
      "loss": 0.8536,
      "step": 3400
    },
    {
      "epoch": 1.0,
      "eval_runtime": 30.3487,
      "eval_samples_per_second": 201.393,
      "eval_steps_per_second": 12.587,
      "step": 3438
    }
  ],
  "logging_steps": 50,
  "max_steps": 10314,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3630794615414784.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
