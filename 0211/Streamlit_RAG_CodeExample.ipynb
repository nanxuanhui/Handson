{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c56aa4b",
   "metadata": {},
   "source": [
    "# Streamlit-based RAG with Wikipedia Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd89d4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (1.42.0)\n",
      "Requirement already satisfied: sentence-transformers in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (3.4.1)\n",
      "Requirement already satisfied: faiss-cpu in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (1.10.0)\n",
      "Requirement already satisfied: pyngrok in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (7.2.3)\n",
      "Requirement already satisfied: pandas in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (2.2.3)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from streamlit) (5.5.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from streamlit) (8.1.8)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from streamlit) (2.0.2)\n",
      "Requirement already satisfied: packaging<25,>=20 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from streamlit) (11.1.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from streamlit) (5.29.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from streamlit) (19.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from streamlit) (13.9.4)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from streamlit) (9.0.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from streamlit) (4.12.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from streamlit) (3.1.44)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from streamlit) (6.4.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from sentence-transformers) (4.48.1)\n",
      "Requirement already satisfied: tqdm in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from sentence-transformers) (0.28.0)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from pyngrok) (6.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: jinja2 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from altair<6,>=4.0->streamlit) (3.1.5)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from altair<6,>=4.0->streamlit) (1.24.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: filelock in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.9.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from requests<3,>=2.27->streamlit) (2024.12.14)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from rich<14,>=10.14.0->streamlit) (2.19.1)\n",
      "Requirement already satisfied: networkx in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit sentence-transformers faiss-cpu pyngrok pandas    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9118bb",
   "metadata": {},
   "source": [
    "# Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08b19791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ABSTRACT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20973</td>\n",
       "      <td>Closed-form Marginal Likelihood in Gamma-Poiss...</td>\n",
       "      <td>We present novel understandings of the Gamma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20974</td>\n",
       "      <td>Laboratory mid-IR spectra of equilibrated and ...</td>\n",
       "      <td>Meteorites contain minerals from Solar Syste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20975</td>\n",
       "      <td>Case For Static AMSDU Aggregation in WLANs</td>\n",
       "      <td>Frame aggregation is a mechanism by which mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20976</td>\n",
       "      <td>The $Gaia$-ESO Survey: the inner disk intermed...</td>\n",
       "      <td>Milky Way open clusters are very diverse in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20977</td>\n",
       "      <td>Witness-Functions versus Interpretation-Functi...</td>\n",
       "      <td>Proving that a cryptographic protocol is cor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                              TITLE  \\\n",
       "0  20973  Closed-form Marginal Likelihood in Gamma-Poiss...   \n",
       "1  20974  Laboratory mid-IR spectra of equilibrated and ...   \n",
       "2  20975         Case For Static AMSDU Aggregation in WLANs   \n",
       "3  20976  The $Gaia$-ESO Survey: the inner disk intermed...   \n",
       "4  20977  Witness-Functions versus Interpretation-Functi...   \n",
       "\n",
       "                                            ABSTRACT  \n",
       "0    We present novel understandings of the Gamma...  \n",
       "1    Meteorites contain minerals from Solar Syste...  \n",
       "2    Frame aggregation is a mechanism by which mu...  \n",
       "3    Milky Way open clusters are very diverse in ...  \n",
       "4    Proving that a cryptographic protocol is cor...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"archive/test.csv\" \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "396df077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8989 entries, 0 to 8988\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   ID        8989 non-null   int64 \n",
      " 1   TITLE     8989 non-null   object\n",
      " 2   ABSTRACT  8989 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 210.8+ KB\n",
      "ID          0\n",
      "TITLE       0\n",
      "ABSTRACT    0\n",
      "dtype: int64\n",
      "Total number of rows: 8989\n",
      "Total rows after cleaning: 8989\n"
     ]
    }
   ],
   "source": [
    "# Display dataset info\n",
    "df.info()\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Check total number of rows\n",
    "print(f\"Total number of rows: {len(df)}\")\n",
    "\n",
    "# Remove missing and duplicate values\n",
    "df_cleaned = df.dropna().drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Check cleaned data\n",
    "print(f\"Total rows after cleaning: {len(df_cleaned)}\")\n",
    "df_cleaned.head()\n",
    "\n",
    "df_cleaned.to_csv(\"cleaned_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fab61d",
   "metadata": {},
   "source": [
    "# Implement the Retrieval-Augmented Generation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa530c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample embedding shape: (384,)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load a pre-trained Sentence Transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # Small and efficient model\n",
    "\n",
    "# Example: Convert a sample text into an embedding\n",
    "sample_text = \"This is a test sentence.\"\n",
    "sample_embedding = model.encode(sample_text)\n",
    "\n",
    "# Print the embedding shape\n",
    "print(f\"Sample embedding shape: {sample_embedding.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69747fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus embeddings shape: (8989, 384)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert the 'TITLE' and 'ABSTRACT' columns into embeddings\n",
    "corpus = df_cleaned[\"TITLE\"] + \" \" + df_cleaned[\"ABSTRACT\"]\n",
    "corpus_embeddings = model.encode(corpus.tolist(), convert_to_numpy=True)\n",
    "\n",
    "# Print the shape of the embeddings\n",
    "print(f\"Corpus embeddings shape: {corpus_embeddings.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e48a001b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vectors in FAISS index: 8989\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "# Define the dimension of the embeddings\n",
    "embedding_dim = corpus_embeddings.shape[1]\n",
    "\n",
    "# Create a FAISS index\n",
    "index = faiss.IndexFlatL2(embedding_dim)  # L2 (Euclidean) distance\n",
    "\n",
    "# Add embeddings to the FAISS index\n",
    "index.add(corpus_embeddings)\n",
    "\n",
    "# Check the number of indexed vectors\n",
    "print(f\"Total vectors in FAISS index: {index.ntotal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f7c58fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Provably efficient neural network representation for image classification\n",
      "Abstract:   The state-of-the-art approaches for image classification are based on neural\n",
      "networks. Mathematically, the task of classifying images is equivalent to\n",
      "finding the function that maps an image to the label it is associated with. To\n",
      "rigorously establish the success of neural network methods, we should first\n",
      "prove that the function has an efficient neural network representation, and\n",
      "then design provably efficient training algorithms to find such a\n",
      "representation. Here, we achieve the first goal based on a set of assumptions\n",
      "about the patterns in the images. The validity of these assumptions is very\n",
      "intuitive in many image classification problems, including but not limited to,\n",
      "recognizing handwritten digits.\n",
      "\n",
      "Score: 0.8415294885635376\n",
      "\n",
      "Title: Vector Field Based Neural Networks\n",
      "Abstract:   A novel Neural Network architecture is proposed using the mathematically and\n",
      "physically rich idea of vector fields as hidden layers to perform nonlinear\n",
      "transformations in the data. The data points are interpreted as particles\n",
      "moving along a flow defined by the vector field which intuitively represents\n",
      "the desired movement to enable classification. The architecture moves the data\n",
      "points from their original configuration to anew one following the streamlines\n",
      "of the vector field with the objective of achieving a final configuration where\n",
      "classes are separable. An optimization problem is solved through gradient\n",
      "descent to learn this vector field.\n",
      "\n",
      "Score: 0.9523687362670898\n",
      "\n",
      "Title: Brain Tumor Detection and Classification with Feed Forward Back-Prop Neural Network\n",
      "Abstract:   Brain is an organ that controls activities of all the parts of the body.\n",
      "Recognition of automated brain tumor in Magnetic resonance imaging (MRI) is a\n",
      "difficult task due to complexity of size and location variability. This\n",
      "automatic method detects all the type of cancer present in the body. Previous\n",
      "methods for tumor are time consuming and less accurate. In the present work,\n",
      "statistical analysis morphological and thresholding techniques are used to\n",
      "process the images obtained by MRI. Feed-forward back-prop neural network is\n",
      "used to classify the performance of tumors part of the image. This method\n",
      "results high accuracy and less iterations detection which further reduces the\n",
      "consumption time.\n",
      "\n",
      "Score: 1.0051120519638062\n",
      "\n",
      "Title: Pixel Normalization from Numeric Data as Input to Neural Networks\n",
      "Abstract:   Text to image transformation for input to neural networks requires\n",
      "intermediate steps. This paper attempts to present a new approach to pixel\n",
      "normalization so as to convert textual data into image, suitable as input for\n",
      "neural networks. This method can be further improved by its Graphics Processing\n",
      "Unit (GPU) implementation to provide significant speedup in computational time.\n",
      "\n",
      "Score: 1.0110621452331543\n",
      "\n",
      "Title: Multilayer Perceptron Algebra\n",
      "Abstract:   Artificial Neural Networks(ANN) has been phenomenally successful on various\n",
      "pattern recognition tasks. However, the design of neural networks rely heavily\n",
      "on the experience and intuitions of individual developers. In this article, the\n",
      "author introduces a mathematical structure called MLP algebra on the set of all\n",
      "Multilayer Perceptron Neural Networks(MLP), which can serve as a guiding\n",
      "principle to build MLPs accommodating to the particular data sets, and to build\n",
      "complex MLPs from simpler ones.\n",
      "\n",
      "Score: 1.0330305099487305\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def retrieve_similar_documents(query, top_k=5):\n",
    "    \"\"\"\n",
    "    Given a query, retrieve the most relevant documents from FAISS index.\n",
    "    \n",
    "    Parameters:\n",
    "        query (str): The input query text.\n",
    "        top_k (int): The number of results to retrieve.\n",
    "    \n",
    "    Returns:\n",
    "        list of (title, abstract, score)\n",
    "    \"\"\"\n",
    "    # Convert query to embedding\n",
    "    query_embedding = model.encode([query], convert_to_numpy=True)\n",
    "\n",
    "    # Search FAISS index for the top-k closest vectors\n",
    "    distances, indices = index.search(query_embedding, top_k)\n",
    "\n",
    "    # Retrieve the corresponding titles and abstracts\n",
    "    results = []\n",
    "    for idx, score in zip(indices[0], distances[0]):\n",
    "        title = df_cleaned.iloc[idx][\"TITLE\"]\n",
    "        abstract = df_cleaned.iloc[idx][\"ABSTRACT\"]\n",
    "        results.append((title, abstract, score))\n",
    "\n",
    "    return results\n",
    "\n",
    "# Test the retrieval function\n",
    "query_text = \"Neural networks for image processing\"\n",
    "results = retrieve_similar_documents(query_text)\n",
    "\n",
    "# Display results\n",
    "for title, abstract, score in results:\n",
    "    print(f\"Title: {title}\\nAbstract: {abstract}\\nScore: {score}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503d13e0",
   "metadata": {},
   "source": [
    "# Build the Streamlit Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6168214",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8502\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://10.10.68.98:8502\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  For better performance, install the Watchdog module:\u001b[0m\n",
      "\n",
      "  $ xcode-select --install\n",
      "  $ pip install watchdog\n",
      "            \u001b[0m\n",
      "^C\n",
      "\u001b[34m  Stopping...\u001b[0m\n",
      "Exception ignored in: <module 'threading' from '/Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/threading.py'>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/threading.py\", line 1477, in _shutdown\n",
      "    lock.acquire()\n",
      "  File \"/Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages/streamlit/web/bootstrap.py\", line 44, in signal_handler\n",
      "    server.stop()\n",
      "  File \"/Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages/streamlit/web/server/server.py\", line 470, in stop\n",
      "    self._runtime.stop()\n",
      "  File \"/Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/site-packages/streamlit/runtime/runtime.py\", line 337, in stop\n",
      "    async_objs.eventloop.call_soon_threadsafe(stop_on_eventloop)\n",
      "  File \"/Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/asyncio/base_events.py\", line 796, in call_soon_threadsafe\n",
      "    self._check_closed()\n",
      "  File \"/Users/nanxuan/miniconda3/envs/dscapstone/lib/python3.9/asyncio/base_events.py\", line 515, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n"
     ]
    }
   ],
   "source": [
    "!streamlit run app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dd010e",
   "metadata": {},
   "source": [
    "# Deploy the Application Using ngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3586cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Public URL: NgrokTunnel: \"https://5115-134-193-197-212.ngrok-free.app\" -> \"http://localhost:8501\"\n",
      "  Stopping...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Keep the notebook running to prevent termination\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 32\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  You can now view your Streamlit app in your browser.\n",
      "\n",
      "  Local URL: http://localhost:8502\n",
      "  Network URL: http://10.10.68.98:8502\n",
      "\n",
      "  For better performance, install the Watchdog module:\n",
      "\n",
      "  $ xcode-select --install\n",
      "  $ pip install watchdog\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import threading\n",
    "import streamlit as st\n",
    "from pyngrok import ngrok\n",
    "\n",
    "# Ensure Streamlit app is written in `app.py`\n",
    "streamlit_script = \"app.py\"\n",
    "\n",
    "# Run Streamlit as a background process\n",
    "def run_streamlit():\n",
    "    os.system(f\"streamlit run {streamlit_script}\")\n",
    "\n",
    "# Start Streamlit in a separate thread\n",
    "thread = threading.Thread(target=run_streamlit)\n",
    "thread.daemon = True\n",
    "thread.start()\n",
    "\n",
    "# Authenticate Ngrok (Replace with your token)\n",
    "NGROK_AUTH_TOKEN = \"2sufQy1aFtFgngqGBdhpTMIZ95Y_3wjyKE1hhwykQszxurVyL\" \n",
    "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
    "\n",
    "# Ensure no previous Ngrok tunnels are running\n",
    "ngrok.kill()\n",
    "\n",
    "# Create a public URL using Ngrok\n",
    "public_url = ngrok.connect(8501, \"http\")\n",
    "print(f\"Public URL: {public_url}\")\n",
    "\n",
    "# Keep the notebook running to prevent termination\n",
    "while True:\n",
    "    time.sleep(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dscapstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
